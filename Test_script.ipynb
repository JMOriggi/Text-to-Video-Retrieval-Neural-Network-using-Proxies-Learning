{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Core modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CONFIG\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import yaml\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "config = edict()\n",
    "\n",
    "config.WORKERS = 16\n",
    "config.LOG_DIR = ''\n",
    "config.MODEL_DIR = ''\n",
    "config.RESULT_DIR = ''\n",
    "config.DATA_DIR = ''\n",
    "config.VERBOSE = False\n",
    "config.TAG = ''\n",
    "\n",
    "# CUDNN related params\n",
    "config.CUDNN = edict()\n",
    "config.CUDNN.BENCHMARK = True\n",
    "config.CUDNN.DETERMINISTIC = False\n",
    "config.CUDNN.ENABLED = True\n",
    "\n",
    "# TAN related params\n",
    "config.TAN = edict()\n",
    "config.TAN.FRAME_MODULE = edict()\n",
    "config.TAN.FRAME_MODULE.NAME = ''\n",
    "config.TAN.FRAME_MODULE.PARAMS = None\n",
    "config.TAN.PROP_MODULE = edict()\n",
    "config.TAN.PROP_MODULE.NAME = ''\n",
    "config.TAN.PROP_MODULE.PARAMS = None\n",
    "config.TAN.FUSION_MODULE = edict()\n",
    "config.TAN.FUSION_MODULE.NAME = ''\n",
    "config.TAN.FUSION_MODULE.PARAMS = None\n",
    "config.TAN.MAP_MODULE = edict()\n",
    "config.TAN.MAP_MODULE.NAME = ''\n",
    "config.TAN.MAP_MODULE.PARAMS = None\n",
    "config.TAN.PRED_INPUT_SIZE = 512\n",
    "\n",
    "# common params for NETWORK\n",
    "config.MODEL = edict()\n",
    "config.MODEL.NAME = ''\n",
    "config.MODEL.CHECKPOINT = '' # The checkpoint for the best performance\n",
    "\n",
    "# DATASET related params\n",
    "config.DATASET = edict()\n",
    "config.DATASET.ROOT = ''\n",
    "config.DATASET.NAME = ''\n",
    "config.DATASET.MODALITY = ''\n",
    "config.DATASET.VIS_INPUT_TYPE = ''\n",
    "config.DATASET.NO_VAL = False\n",
    "config.DATASET.BIAS = 0\n",
    "config.DATASET.NUM_SAMPLE_CLIPS = 256\n",
    "config.DATASET.TARGET_STRIDE = 16\n",
    "config.DATASET.DOWNSAMPLING_STRIDE = 16\n",
    "config.DATASET.SPLIT = ''\n",
    "config.DATASET.NORMALIZE = False\n",
    "config.DATASET.RANDOM_SAMPLING = False\n",
    "\n",
    "# train\n",
    "config.TRAIN = edict()\n",
    "config.TRAIN.LR = 0.001\n",
    "config.TRAIN.WEIGHT_DECAY = 0\n",
    "config.TRAIN.FACTOR = 0.8\n",
    "config.TRAIN.PATIENCE = 20\n",
    "config.TRAIN.MAX_EPOCH = 20\n",
    "config.TRAIN.BATCH_SIZE = 4\n",
    "config.TRAIN.SHUFFLE = True\n",
    "config.TRAIN.CONTINUE = False\n",
    "\n",
    "config.LOSS = edict()\n",
    "config.LOSS.NAME = 'bce_loss'\n",
    "config.LOSS.PARAMS = None\n",
    "\n",
    "# test\n",
    "config.TEST = edict()\n",
    "config.TEST.RECALL = []\n",
    "config.TEST.TIOU = []\n",
    "config.TEST.NMS_THRESH = 0.4\n",
    "config.TEST.INTERVAL = 1\n",
    "config.TEST.EVAL_TRAIN = False\n",
    "config.TEST.BATCH_SIZE = 1\n",
    "config.TEST.TOP_K = 10\n",
    "\n",
    "def _update_dict(cfg, value):\n",
    "    for k, v in value.items():\n",
    "        if k in cfg:\n",
    "            if k == 'PARAMS':\n",
    "                cfg[k] = v\n",
    "            elif isinstance(v, dict):\n",
    "                _update_dict(cfg[k],v)\n",
    "            else:\n",
    "                cfg[k] = v\n",
    "        else:\n",
    "            raise ValueError(\"{} not exist in config.py\".format(k))\n",
    "\n",
    "def update_config(config_file):\n",
    "    with open(config_file) as f:\n",
    "        exp_config = edict(yaml.load(f, Loader=yaml.FullLoader))\n",
    "        for k, v in exp_config.items():\n",
    "            if k in config:\n",
    "                if isinstance(v, dict):\n",
    "                    _update_dict(config[k], v)\n",
    "                else:\n",
    "                    config[k] = v\n",
    "            else:\n",
    "                raise ValueError(\"{} not exist in config.py\".format(k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --cfg CFG\n",
      "ipykernel_launcher.py: error: the following arguments are required: --cfg\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.7/python3/3.7.9/install/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3425: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Eval: only things needed\n",
    "\"\"\"\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "#from terminaltables import AsciiTable #!pip install terminaltables\n",
    "'''\n",
    "from core.config import config, update_config\n",
    "'''\n",
    "\n",
    "def iou(pred, gt): # require pred and gt is numpy\n",
    "    assert isinstance(pred, list) and isinstance(gt,list)\n",
    "    pred_is_list = isinstance(pred[0],list)\n",
    "    gt_is_list = isinstance(gt[0],list)\n",
    "    if not pred_is_list: pred = [pred]\n",
    "    if not gt_is_list: gt = [gt]\n",
    "    pred, gt = np.array(pred), np.array(gt)\n",
    "    inter_left = np.maximum(pred[:,0,None], gt[None,:,0])\n",
    "    inter_right = np.minimum(pred[:,1,None], gt[None,:,1])\n",
    "    inter = np.maximum(0.0, inter_right - inter_left)\n",
    "    union_left = np.minimum(pred[:,0,None], gt[None,:,0])\n",
    "    union_right = np.maximum(pred[:,1,None], gt[None,:,1])\n",
    "    union = np.maximum(0.0, union_right - union_left)\n",
    "    overlap = 1.0 * inter / union\n",
    "    if not gt_is_list:\n",
    "        overlap = overlap[:,0]\n",
    "    if not pred_is_list:\n",
    "        overlap = overlap[0]\n",
    "    return overlap\n",
    "\n",
    "\n",
    "def rank(pred, gt):\n",
    "    return pred.index(gt) + 1\n",
    "\n",
    "def nms(dets, thresh=0.4, top_k=-1):\n",
    "    \"\"\"Pure Python NMS baseline.\"\"\"\n",
    "    if len(dets) == 0: return []\n",
    "    order = np.arange(0,len(dets),1)\n",
    "    dets = np.array(dets)\n",
    "    x1 = dets[:, 0]\n",
    "    x2 = dets[:, 1]\n",
    "    lengths = x2 - x1\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        if len(keep) == top_k:\n",
    "            break\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        inter = np.maximum(0.0, xx2 - xx1)\n",
    "        ovr = inter / (lengths[i] + lengths[order[1:]] - inter)\n",
    "        inds = np.where(ovr <= thresh)[0]\n",
    "        order = order[inds + 1]\n",
    "\n",
    "    return dets[keep]\n",
    "\n",
    "def eval(segments, data):\n",
    "    tious = [float(i) for i in config.TEST.TIOU.split(',')] if isinstance(config.TEST.TIOU,str) else [config.TEST.TIOU]\n",
    "    recalls = [int(i) for i in config.TEST.RECALL.split(',')] if isinstance(config.TEST.RECALL,str) else [config.TEST.RECALL]\n",
    "\n",
    "    eval_result = [[[] for _ in recalls] for _ in tious]\n",
    "    max_recall = max(recalls)\n",
    "    average_iou = []\n",
    "    for seg, dat in zip(segments, data):\n",
    "        seg = nms(seg, thresh=config.TEST.NMS_THRESH, top_k=max_recall).tolist()\n",
    "        overlap = iou(seg, [dat['times']])\n",
    "        average_iou.append(np.mean(np.sort(overlap[0])[-3:]))\n",
    "\n",
    "        for i,t in enumerate(tious):\n",
    "            for j,r in enumerate(recalls):\n",
    "                eval_result[i][j].append((overlap > t)[:r].any())\n",
    "    eval_result = np.array(eval_result).mean(axis=-1)\n",
    "    miou = np.mean(average_iou)\n",
    "\n",
    "\n",
    "    return eval_result, miou\n",
    "\n",
    "def eval_predictions(segments, data, verbose=True):\n",
    "    eval_result, miou = eval(segments, data)\n",
    "    if verbose:\n",
    "        print(display_results(eval_result, miou, ''))\n",
    "\n",
    "    return eval_result, miou\n",
    "\n",
    "def display_results(eval_result, miou, title=None):\n",
    "    tious = [float(i) for i in config.TEST.TIOU.split(',')] if isinstance(config.TEST.TIOU,str) else [config.TEST.TIOU]\n",
    "    recalls = [int(i) for i in config.TEST.RECALL.split(',')] if isinstance(config.TEST.RECALL,str) else [config.TEST.RECALL]\n",
    "\n",
    "    display_data = [['Rank@{},mIoU@{}'.format(i,j) for i in recalls for j in tious]+['mIoU']]\n",
    "    eval_result = eval_result*100\n",
    "    miou = miou*100\n",
    "    display_data.append(['{:.02f}'.format(eval_result[j][i]) for i in range(len(recalls)) for j in range(len(tious))]\n",
    "                        +['{:.02f}'.format(miou)])\n",
    "    print(display_data)\n",
    "    #table = AsciiTable(display_data, title)\n",
    "    #for i in range(len(tious)*len(recalls)):\n",
    "    #    table.justify_columns[i] = 'center'\n",
    "    return table.table\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Train localization network')\n",
    "\n",
    "    # general\n",
    "    parser.add_argument('--cfg', help='experiment configure file name', required=True, type=str)\n",
    "    args, rest = parser.parse_known_args()\n",
    "\n",
    "    # update config\n",
    "    update_config(args.cfg)\n",
    "\n",
    "    parser.add_argument('--verbose', default=False, action=\"store_true\", help='print progress bar')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "\n",
    "def reset_config(config, args):\n",
    "    if args.verbose:\n",
    "        config.VERBOSE = args.verbose\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "    reset_config(config, args)\n",
    "    train_data = json.load(open('/data/home2/hacker01/Data/DiDeMo/train_data.json', 'r'))\n",
    "    val_data = json.load(open('/data/home2/hacker01/Data/DiDeMo/val_data.json', 'r'))\n",
    "\n",
    "    moment_frequency_dict = {}\n",
    "    for d in train_data:\n",
    "        times = [t for t in d['times']]\n",
    "        for time in times:\n",
    "            time = tuple(time)\n",
    "            if time not in moment_frequency_dict.keys():\n",
    "                moment_frequency_dict[time] = 0\n",
    "            moment_frequency_dict[time] += 1\n",
    "\n",
    "    prior = sorted(moment_frequency_dict, key=moment_frequency_dict.get, reverse=True)\n",
    "    prior = [list(item) for item in prior]\n",
    "    prediction = [prior for d in val_data]\n",
    "\n",
    "    eval_predictions(prediction, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Engine class\n",
    "\"\"\"\n",
    "class Engine(object):\n",
    "    def __init__(self):\n",
    "        self.hooks = {}\n",
    "\n",
    "    def hook(self, name, state):\n",
    "\n",
    "        if name in self.hooks:\n",
    "            self.hooks[name](state)\n",
    "\n",
    "    def train(self, network, iterator, maxepoch, optimizer, scheduler):\n",
    "        state = {\n",
    "            'network': network,\n",
    "            'iterator': iterator,\n",
    "            'maxepoch': maxepoch,\n",
    "            'optimizer': optimizer,\n",
    "            'scheduler': scheduler,\n",
    "            'epoch': 0,\n",
    "            't': 0,\n",
    "            'train': True,\n",
    "        }\n",
    "\n",
    "        self.hook('on_start', state)\n",
    "        while state['epoch'] < state['maxepoch']:\n",
    "            print(f\"EPOCH {state['epoch']}/{state['maxepoch']}\")\n",
    "            self.hook('on_start_epoch', state)\n",
    "            for sample in state['iterator']:\n",
    "                state['sample'] = sample\n",
    "                self.hook('on_sample', state)\n",
    "\n",
    "                def closure():\n",
    "                    loss, output = state['network'](state['sample'])\n",
    "                    state['output'] = output\n",
    "                    state['loss'] = loss\n",
    "                    loss.backward()\n",
    "                    self.hook('on_forward', state)\n",
    "                    # to free memory in save_for_backward\n",
    "                    state['output'] = None\n",
    "                    state['loss'] = None\n",
    "                    return loss\n",
    "\n",
    "                state['optimizer'].zero_grad()\n",
    "                state['optimizer'].step(closure)\n",
    "                self.hook('on_update', state)\n",
    "                state['t'] += 1\n",
    "            state['epoch'] += 1\n",
    "            self.hook('on_end_epoch', state)\n",
    "        self.hook('on_end', state)\n",
    "        return state\n",
    "\n",
    "    def test(self, network, iterator, split):\n",
    "        state = {\n",
    "            'network': network,\n",
    "            'iterator': iterator,\n",
    "            'split': split,\n",
    "            't': 0,\n",
    "            'train': False,\n",
    "        }\n",
    "\n",
    "        self.hook('on_test_start', state)\n",
    "        for sample in state['iterator']:\n",
    "            state['sample'] = sample\n",
    "            self.hook('on_test_sample', state)\n",
    "\n",
    "            def closure():\n",
    "                loss, output = state['network'](state['sample'])\n",
    "                state['output'] = output\n",
    "                state['loss'] = loss\n",
    "                self.hook('on_test_forward', state)\n",
    "                # to free memory in save_for_backward\n",
    "                state['output'] = None\n",
    "                state['loss'] = None\n",
    "\n",
    "            closure()\n",
    "            state['t'] += 1\n",
    "        self.hook('on_test_end', state)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "utils modules\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def create_logger(cfg, cfg_name, tag='train'):\n",
    "    root_log_dir = Path(cfg.LOG_DIR)\n",
    "    # set up logger\n",
    "    if not root_log_dir.exists():\n",
    "        print('=> creating {}'.format(root_log_dir))\n",
    "        root_log_dir.mkdir()\n",
    "\n",
    "    dataset = cfg.DATASET.NAME\n",
    "    cfg_name = os.path.basename(cfg_name).split('.yaml')[0]\n",
    "\n",
    "    final_log_dir = root_log_dir / dataset / cfg_name\n",
    "\n",
    "    print('=> creating {}'.format(final_log_dir))\n",
    "    final_log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    time_str = time.strftime('%Y-%m-%d-%H-%M')\n",
    "    log_file = '{}_{}_{}.log'.format(cfg_name, time_str, tag)\n",
    "    final_log_file = final_log_dir / log_file\n",
    "    head = '%(asctime)-15s %(message)s'\n",
    "    logging.basicConfig(filename=str(final_log_file), format=head)\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    console = logging.StreamHandler()\n",
    "    logging.getLogger('').addHandler(console)\n",
    "\n",
    "    return logger, str(final_log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Path to dataset files\n",
    "\"\"\"\n",
    "class Path(object):\n",
    "    ## Dataset files\n",
    "    @staticmethod\n",
    "    def annotations_file():\n",
    "        ## [video name] [start time] [end time]##[sentence]\n",
    "        return ('/projectnb/cs591-mm-ml/KuJu/dataset_charades_sta/charades_sta_train.txt',\n",
    "                '/projectnb/cs591-mm-ml/KuJu/dataset_charades_sta/charades_sta_test.txt')\n",
    "    @staticmethod\n",
    "    def infos_file():\n",
    "        ## id,subject,scene,quality,relevance,verified,script,objects,descriptions,actions,length\n",
    "        return ('/projectnb/cs591-mm-ml/KuJu/dataset_charades_sta/charades_sta_infos_train.csv',\n",
    "                '/projectnb/cs591-mm-ml/KuJu/dataset_charades_sta/charades_sta_infos_test.csv')\n",
    "    @staticmethod\n",
    "    def video_folder():\n",
    "        return '/projectnb/cs591-mm-ml/KuJu/dataset_charades_sta/charades_480/'\n",
    "    @staticmethod\n",
    "    def c3d_model_file():\n",
    "        return 'c3d.pickle'\n",
    "    @staticmethod\n",
    "    def embedding_file():\n",
    "        return '/projectnb/cs591-mm-ml/KuJu/word_embedding/glove.6B.300d.txt'\n",
    "    \n",
    "    ## CONFIG init\n",
    "    @staticmethod\n",
    "    def config_init_1():\n",
    "        return '2D-TAN-16x16-K5L8-conv.yaml'\n",
    "    @staticmethod\n",
    "    def config_init_2():\n",
    "        return '2D-TAN-16x16-K5L8-pool.yaml'\n",
    "    \n",
    "    \n",
    "    ## Generated\n",
    "    @staticmethod\n",
    "    def word2id_file():\n",
    "        return '/projectnb/cs591-mm-ml/KuJu/dataset_charades_sta/word2id.json'\n",
    "    @staticmethod\n",
    "    def video_features_folder():\n",
    "        return '/projectnb/cs591-mm-ml/KuJu/dataset_charades_sta/video_features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Init Dataset modules\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#from core.config import config\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch_word_vectors = [b['word_vectors'] for b in batch]\n",
    "    batch_txt_mask = [b['txt_mask'] for b in batch]\n",
    "    batch_map_gt = [b['map_gt'] for b in batch]\n",
    "    batch_anno_idxs = [b['anno_idx'] for b in batch]\n",
    "    batch_vis_feats = [b['visual_input'] for b in batch]\n",
    "    batch_duration = [b['duration'] for b in batch]\n",
    "\n",
    "    max_num_clips = max([map_gt.shape[-1] for map_gt in batch_map_gt])\n",
    "    padded_batch_map_gt = torch.zeros(len(batch_map_gt), 1, max_num_clips, max_num_clips)\n",
    "    for i, map_gt in enumerate(batch_map_gt):\n",
    "        num_clips = map_gt.shape[-1]\n",
    "        padded_batch_map_gt[i][0,:num_clips,:num_clips] = map_gt\n",
    "\n",
    "    batch_data = {\n",
    "        'batch_anno_idxs': batch_anno_idxs,\n",
    "        'batch_word_vectors': nn.utils.rnn.pad_sequence(batch_word_vectors, batch_first=True),\n",
    "        'batch_txt_mask': nn.utils.rnn.pad_sequence(batch_txt_mask, batch_first=True),\n",
    "        'batch_map_gt': padded_batch_map_gt,\n",
    "        'batch_vis_input': nn.utils.rnn.pad_sequence(batch_vis_feats, batch_first=True).float(),\n",
    "        'batch_duration': batch_duration,\n",
    "    }\n",
    "\n",
    "    return batch_data\n",
    "\n",
    "def average_to_fixed_length(visual_input):\n",
    "    num_sample_clips = config.DATASET.NUM_SAMPLE_CLIPS\n",
    "    num_clips = visual_input.shape[0]\n",
    "    idxs = torch.arange(0, num_sample_clips+1, 1.0)/num_sample_clips*num_clips\n",
    "    idxs = torch.min(torch.round(idxs).long(),torch.tensor(num_clips-1))\n",
    "    new_visual_input = []\n",
    "    for i in range(num_sample_clips):\n",
    "        s_idx, e_idx = idxs[i].item(), idxs[i+1].item()\n",
    "        if s_idx < e_idx:\n",
    "            new_visual_input.append(torch.mean(visual_input[s_idx:e_idx],dim=0))\n",
    "        else:\n",
    "            new_visual_input.append(visual_input[s_idx])\n",
    "    new_visual_input = torch.stack(new_visual_input, dim=0)\n",
    "    return new_visual_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The C3D network.\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class C3D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C3D, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(3, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "\n",
    "        self.conv2 = nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "\n",
    "        self.conv3a = nn.Conv3d(128, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv3b = nn.Conv3d(256, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "\n",
    "        self.conv4a = nn.Conv3d(256, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv4b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool4 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "\n",
    "        self.conv5a = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv5b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool5 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 1, 1))\n",
    "\n",
    "        self.fc6 = nn.Linear(8192, 4096)\n",
    "        self.fc7 = nn.Linear(4096, 4096)\n",
    "        self.fc8 = nn.Linear(4096, 487)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        forward pass without the lasts layers.\n",
    "        '''\n",
    "        h = self.relu(self.conv1(x))\n",
    "        h = self.pool1(h)\n",
    "\n",
    "        h = self.relu(self.conv2(h))\n",
    "        h = self.pool2(h)\n",
    "\n",
    "        h = self.relu(self.conv3a(h))\n",
    "        h = self.relu(self.conv3b(h))\n",
    "        h = self.pool3(h)\n",
    "\n",
    "        h = self.relu(self.conv4a(h))\n",
    "        h = self.relu(self.conv4b(h))\n",
    "        h = self.pool4(h)\n",
    "\n",
    "        h = self.relu(self.conv5a(h))\n",
    "        h = self.relu(self.conv5b(h))\n",
    "        h = self.pool5(h)\n",
    "\n",
    "        h = h.view(-1, 8192)\n",
    "        h = self.fc6(h)\n",
    "        h = self.relu(h)\n",
    "\n",
    "        # h = self.dropout(h)\n",
    "        # h = self.relu(self.fc7(h))\n",
    "        # h = self.dropout(h)\n",
    "\n",
    "        # logits = self.fc8(h)\n",
    "        # probs = self.softmax(logits)\n",
    "\n",
    "        # return probs\n",
    "        return h.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Dataset loader for the Charades-STA dataset \n",
    "\"\"\"\n",
    "import os\n",
    "import csv\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torchtext import vocab\n",
    "\n",
    "import cv2\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Custom module dependencies\n",
    "'''from . import average_to_fixed_length # \"from .\" means from init\n",
    "from core.eval import iou\n",
    "from core.config import config\n",
    "from path import Path as PATH\n",
    "from C3D_model import C3D'''\n",
    "PATH = Path()\n",
    "\n",
    "class Charades(data.Dataset):\n",
    "\n",
    "    ## Embedding from torchtext lib\n",
    "    vocab = vocab.pretrained_aliases[\"glove.6B.300d\"]()\n",
    "    vocab.itos.extend(['<unk>'])\n",
    "    vocab.stoi['<unk>'] = vocab.vectors.shape[0]\n",
    "    vocab.vectors = torch.cat([vocab.vectors, torch.zeros(1, vocab.dim)], dim=0)\n",
    "    word_embedding = nn.Embedding.from_pretrained(vocab.vectors)\n",
    "    ## Embedding from file\n",
    "    '''with open(PATH.embedding_file(),'r') as f:\n",
    "        vocab = f.readlines()\n",
    "    vocab = {line.split()[0]:np.asarray(line.split()[1:], \"float32\") for line in vocab}\n",
    "    vocab['<unk>'] = np.zeros([1, 300], dtype = \"float32\")\n",
    "    word_embedding = nn.Embedding.from_pretrained(torch.Tensor(list(glove.values())))'''\n",
    "\n",
    "    def __init__(self, split):\n",
    "        super(Charades, self).__init__()\n",
    "\n",
    "        ## Init vars\n",
    "        #self.vis_input_type = config.DATASET.VIS_INPUT_TYPE\n",
    "        #self.data_dir = config.DATA_DIR\n",
    "        self.split = split\n",
    "\n",
    "        ## Get duration\n",
    "        self.durations = {}\n",
    "        with open(PATH.infos_file()[self.split]) as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                self.durations[row['id']] = float(row['length'])\n",
    "\n",
    "        ## Get annotations and infos\n",
    "        anno_file = open(PATH.annotations_file()[self.split],'r')\n",
    "        annotations = []\n",
    "        for line in anno_file:\n",
    "            anno, sent = line.split(\"##\")\n",
    "            sent = sent.split('.\\n')[0]\n",
    "            vid, s_time, e_time = anno.split(\" \")\n",
    "            s_time = float(s_time)\n",
    "            e_time = min(float(e_time), self.durations[vid])\n",
    "            if s_time < e_time:\n",
    "                annotations.append({'video':vid, 'times':[s_time, e_time], 'description': sent, 'duration': self.durations[vid]})\n",
    "        anno_file.close()\n",
    "        self.annotations = annotations\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ## Init Vars\n",
    "        video_id = self.annotations[index]['video']\n",
    "        gt_s_time, gt_e_time = self.annotations[index]['times']\n",
    "        description = self.annotations[index]['description']\n",
    "        duration = self.annotations[index]['duration'] \n",
    "        \n",
    "        ## Get Word Features\n",
    "        word_idxs = torch.tensor([self.vocab.stoi.get(w.lower(), 400000) for w in description.split()], dtype=torch.long)\n",
    "        #word_idxs = torch.tensor([list(self.vocab.keys()).index(w.lower()) if w in list(self.vocab.keys()) else list(self.vocab.keys()).index('<unk>') for w in description.split()], dtype=torch.long)\n",
    "        word_vectors = self.word_embedding(word_idxs)\n",
    "\n",
    "        ## Get Video Features\n",
    "        visual_input, visual_mask = self.get_video_features(video_id)\n",
    "        \n",
    "        # Time scaled to same size\n",
    "        if config.DATASET.NUM_SAMPLE_CLIPS > 0:\n",
    "            # visual_input = sample_to_fixed_length(visual_input, random_sampling=True)\n",
    "            visual_input = average_to_fixed_length(visual_input)\n",
    "            num_clips = config.DATASET.NUM_SAMPLE_CLIPS//config.DATASET.TARGET_STRIDE\n",
    "            s_times = torch.arange(0,num_clips).float()*duration/num_clips\n",
    "            e_times = torch.arange(1,num_clips+1).float()*duration/num_clips\n",
    "            overlaps = iou(torch.stack([s_times[:,None].expand(-1,num_clips),\n",
    "                                        e_times[None,:].expand(num_clips,-1)],dim=2).view(-1,2).tolist(),\n",
    "                           torch.tensor([gt_s_time, gt_e_time]).tolist()).reshape(num_clips,num_clips)\n",
    "\n",
    "        # Time unscaled NEED FIXED WINDOW SIZE\n",
    "        else:\n",
    "            num_clips = visual_input.shape[0]//config.DATASET.TARGET_STRIDE\n",
    "            raise NotImplementedError\n",
    "\n",
    "        item = {\n",
    "            'visual_input': visual_input,\n",
    "            'vis_mask': visual_mask,\n",
    "            'anno_idx': index,\n",
    "            'word_vectors': word_vectors,\n",
    "            'duration': duration,\n",
    "            'txt_mask': torch.ones(word_vectors.shape[0], 1),\n",
    "            'map_gt': torch.from_numpy(overlaps),\n",
    "        }\n",
    "\n",
    "        return item\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def get_video_features(self, vid):\n",
    "        #assert config.DATASET.VIS_INPUT_TYPE == 'c3d'\n",
    "        #with h5py.File(os.path.join(self.data_dir, 'sub_activitynet_v1-3.c3d.hdf5'), 'r') as f:\n",
    "        #    features = torch.from_numpy(f[vid]['c3d_features'][:])\n",
    "        if os.path.exists(PATH.video_features_folder() + vid + '.npy'):\n",
    "            ## If features file exist\n",
    "            #print(f'Feature file for {vid} exists')\n",
    "            features = np.load(PATH.video_features_folder() + vid + '.npy')\n",
    "            features = torch.from_numpy(features)\n",
    "        elif os.path.exists(PATH.video_folder() + vid + '.mp4'):\n",
    "            ## If not compute at the moment from .mp4 video\n",
    "            #print(f'Extract features from raw video for {vid}')\n",
    "            features = self.extract_from_raw_video(PATH.video_folder() + vid + '.mp4', vid)\n",
    "            features = torch.from_numpy(features)\n",
    "        \n",
    "        #if config.DATASET.NORMALIZE:\n",
    "        #    features = F.normalize(features,dim=1)\n",
    "            \n",
    "        vis_mask = torch.ones((features.shape[0], 1))\n",
    "        return features, vis_mask\n",
    "    \n",
    "\n",
    "    def extract_from_raw_video(self, input_path, vid):\n",
    "        '''\n",
    "        3D CNN expects input like [batch, channels, clip_frames, H, W]\n",
    "        From cv2 I obtain [frames, channels, H, W]\n",
    "        Transform it to [clip, clip_frames, channels, H, W]\n",
    "        By consequence I consider a batch as a number of clips of frames (batch-->clips-->frames)\n",
    "        '''\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        transform = transforms.Compose([transforms.Resize(224), transforms.CenterCrop(224), transforms.ToTensor(), normalize])\n",
    "        #transform = transforms.Compose([transforms.Resize(224), transforms.CenterCrop(224), transforms.ToTensor()])\n",
    "    \n",
    "        ## Extract frames images from video\n",
    "        cap= cv2.VideoCapture(input_path)\n",
    "        frame_list = []\n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            if ret == False:\n",
    "                break\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = Image.fromarray(frame)\n",
    "            #frame.save('test'+str(i)+'.png')\n",
    "            frame = transform(frame)\n",
    "            frame = Variable(frame) #frame.unsqueeze(0).cuda())\n",
    "            frame_list.append(frame)\n",
    "        cap.release()\n",
    "        \n",
    "        ## Clip extracted frames list\n",
    "        clip_size = 16\n",
    "        clip_stride = clip_size #int(clip_size/2) #will trow away last clip_stride frames to have every clip of same lenght\n",
    "        frame_clip_list = [torch.stack(frame_list[x:x+clip_size]) for x in range(0, len(frame_list)-clip_size, clip_stride)]\n",
    "        frame_clip_list = torch.stack(frame_clip_list)\n",
    "        #print(f'All Clips shape: {frame_clip_list.shape}') #torch.Size([62, 16, 3, 224, 224]) [Batches_clips, clips, chan, H, W]\n",
    "        \n",
    "        ## Create batches: I do not use Dataset custom class because only for feature extraction\n",
    "        dataloader = DataLoader(frame_clip_list, batch_size = 16, shuffle = False)\n",
    "        \n",
    "        ## Visualize batch\n",
    "        '''def imshow(img):\n",
    "            #img = img/2 + 0.5 #unnormalize\n",
    "            print(f'Frames plot shape: {img.shape}')\n",
    "            npimg = img.cpu().numpy()\n",
    "            npimg = np.transpose(npimg, (1, 2, 0))\n",
    "            plt.imshow(npimg)\n",
    "        dataiter = iter(dataloader)\n",
    "        clip = dataiter.next() #[clip, depth, in_channels, height, width]\n",
    "        images = clip[0] #[depth, in_channels, height, width]\n",
    "        print(f'One Batch shape: {clip.shape}')\n",
    "        print(f'One Clip shape: {images.shape}')\n",
    "        imshow(torchvision.utils.make_grid(images))'''\n",
    "        \n",
    "        ## Init model\n",
    "        if config.CUDNN.ENABLED:\n",
    "            model = C3D().cuda()\n",
    "            model.load_state_dict(torch.load(PATH.c3d_model_file()))\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            model = torch.nn.DataParallel(model)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "            \n",
    "        ## Extract features for each clip of frames\n",
    "        vis_embed = []\n",
    "        for sample in dataloader: # input: [batch, clip_frames, in_channels, height, width]\n",
    "            with torch.no_grad():\n",
    "                sample = np.transpose(sample, (0, 2, 1, 3, 4)) # swap clip_frames and channels\n",
    "                sample = sample.cuda()\n",
    "                feat = model(sample) #input expected: [batch, in_channels, clip_frames, height, width]\n",
    "                feat = feat.cpu().numpy()\n",
    "            vis_embed.append(feat)\n",
    "        vis_embed = np.vstack(vis_embed)\n",
    "        \n",
    "        ## Save features video in file\n",
    "        output_file_path = PATH.video_features_folder()+vid+'.npy'\n",
    "        np.save(output_file_path, vis_embed)\n",
    "        return vis_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu102\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Charades(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Charades object at 0x2b76c00d7290>\n",
      "12404\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(len(train_dataset.annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract features from raw video for AO8RW\n",
      "Extract features from raw video for Y6R7T\n",
      "Feature file for Y6R7T exists\n",
      "Feature file for Y6R7T exists\n",
      "Feature file for Y6R7T exists\n",
      "Feature file for Y6R7T exists\n",
      "Extract features from raw video for IGDIE\n",
      "Extract features from raw video for 7UPGT\n",
      "Extract features from raw video for KBPDM\n",
      "Feature file for KBPDM exists\n",
      "Feature file for KBPDM exists\n",
      "Extract features from raw video for IBIWF\n",
      "Extract features from raw video for 372CC\n",
      "Feature file for 372CC exists\n",
      "Extract features from raw video for N14BK\n",
      "Extract features from raw video for NQT1S\n",
      "Extract features from raw video for F1VEE\n",
      "Feature file for F1VEE exists\n",
      "Feature file for F1VEE exists\n",
      "Feature file for F1VEE exists\n",
      "Feature file for F1VEE exists\n",
      "Extract features from raw video for YDWN5\n",
      "Extract features from raw video for QRWQ3\n",
      "Feature file for QRWQ3 exists\n",
      "Extract features from raw video for SFHHR\n",
      "Extract features from raw video for HWYTN\n",
      "Feature file for HWYTN exists\n",
      "Feature file for HWYTN exists\n",
      "Extract features from raw video for GG4UR\n",
      "Feature file for GG4UR exists\n",
      "Feature file for GG4UR exists\n",
      "Feature file for GG4UR exists\n",
      "Feature file for GG4UR exists\n",
      "Extract features from raw video for XDVAY\n",
      "Extract features from raw video for MLBTH\n",
      "Feature file for MLBTH exists\n",
      "Feature file for MLBTH exists\n",
      "Extract features from raw video for IR31O\n",
      "Feature file for IR31O exists\n",
      "Extract features from raw video for KX8VW\n",
      "Feature file for KX8VW exists\n",
      "Feature file for KX8VW exists\n",
      "Extract features from raw video for NVBBD\n",
      "Feature file for NVBBD exists\n",
      "Feature file for NVBBD exists\n",
      "Feature file for NVBBD exists\n",
      "Feature file for NVBBD exists\n",
      "Feature file for NVBBD exists\n",
      "Extract features from raw video for 4C4LC\n",
      "Extract features from raw video for J4GX8\n",
      "Feature file for J4GX8 exists\n",
      "Feature file for J4GX8 exists\n",
      "Feature file for J4GX8 exists\n",
      "Extract features from raw video for HPEE5\n",
      "Feature file for HPEE5 exists\n",
      "Extract features from raw video for MBGPJ\n",
      "Feature file for MBGPJ exists\n",
      "Feature file for MBGPJ exists\n",
      "Extract features from raw video for NEM29\n",
      "Feature file for NEM29 exists\n",
      "Extract features from raw video for SA7GL\n",
      "Feature file for SA7GL exists\n",
      "Feature file for SA7GL exists\n",
      "Extract features from raw video for 0QA8P\n",
      "Feature file for 0QA8P exists\n",
      "Feature file for 0QA8P exists\n",
      "Extract features from raw video for BWHUX\n",
      "Extract features from raw video for KJ8G2\n",
      "Extract features from raw video for D87UN\n",
      "Feature file for D87UN exists\n",
      "Extract features from raw video for XJOJL\n",
      "Feature file for XJOJL exists\n",
      "Extract features from raw video for 67MSU\n",
      "Feature file for 67MSU exists\n",
      "Feature file for 67MSU exists\n",
      "Extract features from raw video for 9NRLA\n",
      "Feature file for 9NRLA exists\n",
      "Feature file for 9NRLA exists\n",
      "Extract features from raw video for I6NJ6\n",
      "Extract features from raw video for KG20W\n",
      "Extract features from raw video for 68JOO\n",
      "Feature file for 68JOO exists\n",
      "Feature file for 68JOO exists\n",
      "Feature file for 68JOO exists\n",
      "Feature file for 68JOO exists\n",
      "Extract features from raw video for QHARF\n",
      "Feature file for QHARF exists\n",
      "Feature file for QHARF exists\n",
      "Extract features from raw video for P1EK9\n",
      "Feature file for P1EK9 exists\n",
      "Feature file for P1EK9 exists\n",
      "Feature file for P1EK9 exists\n",
      "Extract features from raw video for KZSA9\n",
      "Feature file for KZSA9 exists\n",
      "Feature file for KZSA9 exists\n",
      "Extract features from raw video for LQ0LM\n",
      "Feature file for LQ0LM exists\n",
      "Feature file for LQ0LM exists\n",
      "Extract features from raw video for ORW6Y\n",
      "Feature file for ORW6Y exists\n",
      "Extract features from raw video for D8HN1\n",
      "Feature file for D8HN1 exists\n",
      "Feature file for D8HN1 exists\n",
      "Feature file for D8HN1 exists\n",
      "Extract features from raw video for BY6ZZ\n",
      "Extract features from raw video for T8B7B\n",
      "Feature file for T8B7B exists\n",
      "Feature file for T8B7B exists\n",
      "Extract features from raw video for D8OSC\n",
      "Extract features from raw video for TGDWN\n",
      "Extract features from raw video for X2Q00\n",
      "Feature file for X2Q00 exists\n",
      "Feature file for X2Q00 exists\n",
      "Extract features from raw video for S8TT8\n",
      "Feature file for S8TT8 exists\n",
      "Feature file for S8TT8 exists\n",
      "Feature file for S8TT8 exists\n",
      "Extract features from raw video for QG4N1\n",
      "Feature file for QG4N1 exists\n",
      "Extract features from raw video for AOMNM\n",
      "Extract features from raw video for X8MNV\n",
      "Extract features from raw video for NHUV1\n",
      "Extract features from raw video for NNG97\n",
      "Feature file for NNG97 exists\n",
      "Feature file for NNG97 exists\n",
      "Extract features from raw video for A1NKP\n",
      "Extract features from raw video for EDXBD\n",
      "Extract features from raw video for BW5MF\n",
      "Extract features from raw video for UZMMO\n",
      "Feature file for UZMMO exists\n",
      "Feature file for UZMMO exists\n",
      "Extract features from raw video for CHBAS\n",
      "Feature file for CHBAS exists\n",
      "Extract features from raw video for M2F66\n",
      "Feature file for M2F66 exists\n",
      "Feature file for M2F66 exists\n",
      "Feature file for M2F66 exists\n",
      "Feature file for M2F66 exists\n",
      "Feature file for M2F66 exists\n",
      "Extract features from raw video for KMZHU\n",
      "Extract features from raw video for 0CG15\n",
      "Feature file for 0CG15 exists\n",
      "Feature file for 0CG15 exists\n",
      "Extract features from raw video for 9XXJ7\n",
      "Feature file for 9XXJ7 exists\n",
      "Extract features from raw video for HKBKA\n",
      "Extract features from raw video for N39RU\n",
      "Extract features from raw video for E0MK4\n",
      "Extract features from raw video for ECMQU\n",
      "Feature file for ECMQU exists\n",
      "Feature file for ECMQU exists\n",
      "Extract features from raw video for M6LFI\n",
      "Feature file for M6LFI exists\n",
      "Extract features from raw video for 618HP\n",
      "Feature file for 618HP exists\n",
      "Feature file for 618HP exists\n",
      "Extract features from raw video for UVEPN\n",
      "Extract features from raw video for Q8HQM\n",
      "Extract features from raw video for GJJA1\n",
      "Feature file for GJJA1 exists\n",
      "Feature file for GJJA1 exists\n",
      "Extract features from raw video for HMSM8\n",
      "Feature file for HMSM8 exists\n",
      "Feature file for HMSM8 exists\n",
      "Extract features from raw video for 3P8NL\n",
      "Feature file for 3P8NL exists\n",
      "Feature file for 3P8NL exists\n",
      "Extract features from raw video for VSS68\n",
      "Feature file for VSS68 exists\n",
      "Extract features from raw video for P4DL9\n",
      "Feature file for P4DL9 exists\n",
      "Feature file for P4DL9 exists\n",
      "Feature file for P4DL9 exists\n",
      "Extract features from raw video for 5TLQE\n",
      "Feature file for 5TLQE exists\n",
      "Extract features from raw video for LTJEO\n",
      "Feature file for LTJEO exists\n",
      "Feature file for LTJEO exists\n",
      "Feature file for LTJEO exists\n",
      "Feature file for LTJEO exists\n",
      "Extract features from raw video for GIIMN\n",
      "Extract features from raw video for CBVUS\n",
      "Feature file for CBVUS exists\n",
      "Extract features from raw video for DPJH4\n",
      "Feature file for DPJH4 exists\n",
      "Extract features from raw video for W0RSP\n",
      "Extract features from raw video for IH3GN\n",
      "Extract features from raw video for VG94P\n",
      "Feature file for VG94P exists\n",
      "Extract features from raw video for 92TUQ\n",
      "Feature file for 92TUQ exists\n",
      "Extract features from raw video for YEHFQ\n",
      "Feature file for YEHFQ exists\n",
      "Feature file for YEHFQ exists\n",
      "Extract features from raw video for 1E1VE\n",
      "Extract features from raw video for 813XE\n",
      "Feature file for 813XE exists\n",
      "Feature file for 813XE exists\n",
      "Feature file for 813XE exists\n",
      "Extract features from raw video for U896B\n",
      "Extract features from raw video for ZS1P1\n",
      "Feature file for ZS1P1 exists\n",
      "Feature file for ZS1P1 exists\n",
      "Extract features from raw video for FIJ3D\n",
      "Feature file for FIJ3D exists\n",
      "Feature file for FIJ3D exists\n",
      "Feature file for FIJ3D exists\n",
      "Feature file for FIJ3D exists\n",
      "Feature file for FIJ3D exists\n",
      "Extract features from raw video for 0G2SC\n",
      "Extract features from raw video for TANH9\n",
      "Extract features from raw video for WZN0I\n",
      "Feature file for WZN0I exists\n",
      "Feature file for WZN0I exists\n",
      "Extract features from raw video for 1LARL\n",
      "Extract features from raw video for MMFXQ\n",
      "Feature file for MMFXQ exists\n",
      "Extract features from raw video for 9INKU\n",
      "Extract features from raw video for 0S9KN\n",
      "Extract features from raw video for 4UYGY\n",
      "Feature file for 4UYGY exists\n",
      "Feature file for 4UYGY exists\n",
      "Feature file for 4UYGY exists\n",
      "Extract features from raw video for QUGSS\n",
      "Extract features from raw video for WEYV3\n",
      "Feature file for WEYV3 exists\n",
      "Feature file for WEYV3 exists\n",
      "Feature file for WEYV3 exists\n",
      "Feature file for WEYV3 exists\n",
      "Extract features from raw video for V6IIE\n",
      "Feature file for V6IIE exists\n",
      "Feature file for V6IIE exists\n",
      "Feature file for V6IIE exists\n",
      "Feature file for V6IIE exists\n",
      "Extract features from raw video for ZHOP3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature file for ZHOP3 exists\n",
      "Extract features from raw video for 1G9R7\n",
      "Extract features from raw video for HPAYB\n",
      "Extract features from raw video for SKLEN\n",
      "Feature file for SKLEN exists\n",
      "Feature file for SKLEN exists\n",
      "Extract features from raw video for L347E\n",
      "Extract features from raw video for B5YYS\n",
      "Extract features from raw video for 2074D\n",
      "Feature file for 2074D exists\n",
      "Extract features from raw video for 9PAQ4\n",
      "Feature file for 9PAQ4 exists\n",
      "Feature file for 9PAQ4 exists\n",
      "Extract features from raw video for 6AJX0\n",
      "Feature file for 6AJX0 exists\n",
      "Feature file for 6AJX0 exists\n",
      "Extract features from raw video for ACMHK\n",
      "Extract features from raw video for TQGPM\n",
      "Extract features from raw video for AK9IB\n",
      "Extract features from raw video for UQW95\n",
      "Feature file for UQW95 exists\n",
      "Feature file for UQW95 exists\n",
      "Feature file for UQW95 exists\n",
      "Feature file for UQW95 exists\n",
      "Extract features from raw video for BTW1H\n",
      "Feature file for BTW1H exists\n",
      "Extract features from raw video for OE751\n",
      "Feature file for OE751 exists\n",
      "Feature file for OE751 exists\n",
      "Extract features from raw video for Q3HZI\n",
      "Feature file for Q3HZI exists\n",
      "Extract features from raw video for 4P13T\n",
      "Feature file for 4P13T exists\n",
      "Feature file for 4P13T exists\n",
      "Feature file for 4P13T exists\n",
      "Extract features from raw video for VD6P1\n",
      "Extract features from raw video for NYDRK\n",
      "Extract features from raw video for P2DV7\n",
      "Extract features from raw video for TAZGF\n",
      "Feature file for TAZGF exists\n",
      "Feature file for TAZGF exists\n",
      "Extract features from raw video for 1L376\n",
      "Extract features from raw video for MJX48\n",
      "Feature file for MJX48 exists\n",
      "Feature file for MJX48 exists\n",
      "Extract features from raw video for BD0S7\n",
      "Extract features from raw video for K2BY7\n",
      "Extract features from raw video for 0AGCS\n",
      "Extract features from raw video for BRLC0\n",
      "Extract features from raw video for U7RVS\n",
      "Feature file for U7RVS exists\n",
      "Feature file for U7RVS exists\n",
      "Extract features from raw video for QEQJ3\n",
      "Feature file for QEQJ3 exists\n",
      "Feature file for QEQJ3 exists\n",
      "Extract features from raw video for GUCB4\n",
      "Feature file for GUCB4 exists\n",
      "Feature file for GUCB4 exists\n",
      "Feature file for GUCB4 exists\n",
      "Extract features from raw video for YW5C4\n",
      "Feature file for YW5C4 exists\n",
      "Feature file for YW5C4 exists\n",
      "Feature file for YW5C4 exists\n",
      "Extract features from raw video for 2MJ72\n",
      "Feature file for 2MJ72 exists\n",
      "Extract features from raw video for EN80R\n",
      "Feature file for EN80R exists\n",
      "Feature file for EN80R exists\n",
      "Extract features from raw video for PLGZM\n",
      "Feature file for PLGZM exists\n",
      "Extract features from raw video for 3MWAY\n",
      "Feature file for 3MWAY exists\n",
      "Feature file for 3MWAY exists\n",
      "Extract features from raw video for 30TL5\n",
      "Extract features from raw video for WSZSL\n",
      "Feature file for WSZSL exists\n",
      "Extract features from raw video for 54XD1\n",
      "Feature file for 54XD1 exists\n",
      "Feature file for 54XD1 exists\n",
      "Feature file for 54XD1 exists\n",
      "Feature file for 54XD1 exists\n",
      "Extract features from raw video for KZK6W\n",
      "Feature file for KZK6W exists\n",
      "Feature file for KZK6W exists\n",
      "Feature file for KZK6W exists\n",
      "Extract features from raw video for 6FUDS\n",
      "Feature file for 6FUDS exists\n",
      "Feature file for 6FUDS exists\n",
      "Feature file for 6FUDS exists\n",
      "Extract features from raw video for QNUIU\n",
      "Feature file for QNUIU exists\n",
      "Extract features from raw video for 5GPOJ\n",
      "Feature file for 5GPOJ exists\n",
      "Extract features from raw video for CDIW7\n",
      "Extract features from raw video for GLGQJ\n",
      "Feature file for GLGQJ exists\n",
      "Feature file for GLGQJ exists\n",
      "Feature file for GLGQJ exists\n",
      "Extract features from raw video for 7XVS7\n",
      "Feature file for 7XVS7 exists\n",
      "Feature file for 7XVS7 exists\n",
      "Extract features from raw video for ESAIY\n",
      "Feature file for ESAIY exists\n",
      "Feature file for ESAIY exists\n",
      "Extract features from raw video for XFLQH\n",
      "Feature file for XFLQH exists\n",
      "Feature file for XFLQH exists\n",
      "Feature file for XFLQH exists\n",
      "Extract features from raw video for JXF3M\n",
      "Extract features from raw video for JUINA\n",
      "Feature file for JUINA exists\n",
      "Extract features from raw video for TKFY2\n",
      "Extract features from raw video for E6TED\n",
      "Extract features from raw video for 7FNZZ\n",
      "Extract features from raw video for T3FJH\n",
      "Feature file for T3FJH exists\n",
      "Extract features from raw video for ED6VQ\n",
      "Extract features from raw video for 87T5P\n",
      "Feature file for 87T5P exists\n",
      "Extract features from raw video for 2544C\n",
      "Feature file for 2544C exists\n",
      "Feature file for 2544C exists\n",
      "Feature file for 2544C exists\n",
      "Extract features from raw video for EE8OB\n",
      "Feature file for EE8OB exists\n",
      "Extract features from raw video for TLBWW\n",
      "Feature file for TLBWW exists\n",
      "Extract features from raw video for 9HIE0\n",
      "Feature file for 9HIE0 exists\n",
      "Feature file for 9HIE0 exists\n",
      "Extract features from raw video for 04LAX\n",
      "Feature file for 04LAX exists\n",
      "Extract features from raw video for UDDTR\n",
      "Feature file for UDDTR exists\n",
      "Extract features from raw video for XOFEX\n",
      "Extract features from raw video for KZODG\n",
      "Feature file for KZODG exists\n",
      "Feature file for KZODG exists\n",
      "Extract features from raw video for I20N2\n",
      "Feature file for I20N2 exists\n",
      "Feature file for I20N2 exists\n",
      "Extract features from raw video for F9K8L\n",
      "Feature file for F9K8L exists\n",
      "Feature file for F9K8L exists\n",
      "Feature file for F9K8L exists\n",
      "Extract features from raw video for KO80I\n",
      "Extract features from raw video for 1CITG\n",
      "Extract features from raw video for 54VBR\n",
      "Feature file for 54VBR exists\n",
      "Feature file for 54VBR exists\n",
      "Feature file for 54VBR exists\n",
      "Feature file for 54VBR exists\n",
      "Extract features from raw video for 3OUXT\n",
      "Extract features from raw video for TETZ7\n",
      "Extract features from raw video for L5842\n",
      "Feature file for L5842 exists\n",
      "Feature file for L5842 exists\n",
      "Extract features from raw video for WNKL6\n",
      "Feature file for WNKL6 exists\n",
      "Feature file for WNKL6 exists\n",
      "Extract features from raw video for P8ZU6\n",
      "Extract features from raw video for DPBI3\n",
      "Extract features from raw video for Y1FKP\n",
      "Feature file for Y1FKP exists\n",
      "Feature file for Y1FKP exists\n",
      "Feature file for Y1FKP exists\n",
      "Extract features from raw video for NDYOR\n",
      "Extract features from raw video for CX5ZM\n",
      "Extract features from raw video for 0LNLR\n",
      "Extract features from raw video for OHQOO\n",
      "Feature file for OHQOO exists\n",
      "Feature file for OHQOO exists\n",
      "Extract features from raw video for Z60TB\n",
      "Extract features from raw video for 8VWV2\n",
      "Feature file for 8VWV2 exists\n",
      "Feature file for 8VWV2 exists\n",
      "Extract features from raw video for UPJWV\n",
      "Feature file for UPJWV exists\n",
      "Feature file for UPJWV exists\n",
      "Feature file for UPJWV exists\n",
      "Feature file for UPJWV exists\n",
      "Extract features from raw video for ZF5CP\n",
      "Feature file for ZF5CP exists\n",
      "Extract features from raw video for P7RQS\n",
      "Feature file for P7RQS exists\n",
      "Extract features from raw video for VS7DA\n",
      "Feature file for VS7DA exists\n",
      "Feature file for VS7DA exists\n",
      "Feature file for VS7DA exists\n",
      "Feature file for VS7DA exists\n",
      "Feature file for VS7DA exists\n",
      "Extract features from raw video for 72HTA\n",
      "Feature file for 72HTA exists\n",
      "Feature file for 72HTA exists\n",
      "Feature file for 72HTA exists\n",
      "Extract features from raw video for 5QJNP\n",
      "Extract features from raw video for 1K0SU\n",
      "Feature file for 1K0SU exists\n",
      "Extract features from raw video for 3QGLU\n",
      "Feature file for 3QGLU exists\n",
      "Feature file for 3QGLU exists\n",
      "Extract features from raw video for 7WG7A\n",
      "Feature file for 7WG7A exists\n",
      "Extract features from raw video for YKVYR\n",
      "Feature file for YKVYR exists\n",
      "Extract features from raw video for WEU2E\n",
      "Feature file for WEU2E exists\n",
      "Feature file for WEU2E exists\n",
      "Feature file for WEU2E exists\n",
      "Extract features from raw video for 7SXQS\n",
      "Feature file for 7SXQS exists\n",
      "Feature file for 7SXQS exists\n",
      "Feature file for 7SXQS exists\n",
      "Extract features from raw video for PZQ5A\n",
      "Feature file for PZQ5A exists\n",
      "Extract features from raw video for 77HDM\n",
      "Extract features from raw video for 64F1C\n",
      "Feature file for 64F1C exists\n",
      "Extract features from raw video for V2JOF\n",
      "Feature file for V2JOF exists\n",
      "Extract features from raw video for MZGMN\n",
      "Feature file for MZGMN exists\n",
      "Feature file for MZGMN exists\n",
      "Feature file for MZGMN exists\n",
      "Feature file for MZGMN exists\n",
      "Feature file for MZGMN exists\n",
      "Feature file for MZGMN exists\n",
      "Extract features from raw video for O7OD2\n",
      "Feature file for O7OD2 exists\n",
      "Feature file for O7OD2 exists\n",
      "Extract features from raw video for 4878H\n",
      "Feature file for 4878H exists\n",
      "Extract features from raw video for 8NS1G\n",
      "Feature file for 8NS1G exists\n",
      "Extract features from raw video for WF3NY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature file for WF3NY exists\n",
      "Extract features from raw video for NC1OC\n",
      "Feature file for NC1OC exists\n",
      "Feature file for NC1OC exists\n",
      "Feature file for NC1OC exists\n",
      "Extract features from raw video for S1N2U\n",
      "Feature file for S1N2U exists\n",
      "Feature file for S1N2U exists\n",
      "Feature file for S1N2U exists\n",
      "Extract features from raw video for G3CDA\n",
      "Extract features from raw video for 00ZCA\n",
      "Feature file for 00ZCA exists\n",
      "Feature file for 00ZCA exists\n",
      "Feature file for 00ZCA exists\n",
      "Extract features from raw video for R6QCQ\n",
      "Feature file for R6QCQ exists\n",
      "Extract features from raw video for YV521\n",
      "Feature file for YV521 exists\n",
      "Feature file for YV521 exists\n",
      "Feature file for YV521 exists\n",
      "Feature file for YV521 exists\n",
      "Feature file for YV521 exists\n",
      "Extract features from raw video for 67EEN\n",
      "Extract features from raw video for ANJNU\n",
      "Feature file for ANJNU exists\n",
      "Feature file for ANJNU exists\n",
      "Feature file for ANJNU exists\n",
      "Extract features from raw video for J12SC\n",
      "Feature file for J12SC exists\n",
      "Feature file for J12SC exists\n",
      "Feature file for J12SC exists\n",
      "Feature file for J12SC exists\n",
      "Extract features from raw video for U1BQ0\n",
      "Feature file for U1BQ0 exists\n",
      "Extract features from raw video for AADCE\n",
      "Feature file for AADCE exists\n",
      "Feature file for AADCE exists\n",
      "Extract features from raw video for YV0ZX\n",
      "Extract features from raw video for LE5F4\n",
      "Extract features from raw video for BUL4V\n",
      "Feature file for BUL4V exists\n",
      "Feature file for BUL4V exists\n",
      "Extract features from raw video for PP2FF\n",
      "Feature file for PP2FF exists\n",
      "Feature file for PP2FF exists\n",
      "Feature file for PP2FF exists\n",
      "Feature file for PP2FF exists\n",
      "Feature file for PP2FF exists\n",
      "Feature file for PP2FF exists\n",
      "Extract features from raw video for W5GEK\n",
      "Extract features from raw video for JMCRT\n",
      "Feature file for JMCRT exists\n",
      "Feature file for JMCRT exists\n",
      "Feature file for JMCRT exists\n",
      "Extract features from raw video for 0ET8W\n",
      "Extract features from raw video for FV51S\n",
      "Extract features from raw video for Q8UJ8\n",
      "Extract features from raw video for 9GQRI\n",
      "Extract features from raw video for R390Z\n",
      "Extract features from raw video for X6B0P\n",
      "Extract features from raw video for KZPBC\n",
      "Extract features from raw video for U3ANG\n",
      "Feature file for U3ANG exists\n",
      "Feature file for U3ANG exists\n",
      "Extract features from raw video for KA3ER\n",
      "Feature file for KA3ER exists\n",
      "Extract features from raw video for R2KI4\n",
      "Feature file for R2KI4 exists\n",
      "Feature file for R2KI4 exists\n",
      "Extract features from raw video for TVBLW\n",
      "Feature file for TVBLW exists\n",
      "Feature file for TVBLW exists\n",
      "Extract features from raw video for JXKPA\n",
      "Feature file for JXKPA exists\n",
      "Extract features from raw video for S2FLE\n",
      "Feature file for S2FLE exists\n",
      "Feature file for S2FLE exists\n",
      "Extract features from raw video for NALYS\n",
      "Feature file for NALYS exists\n",
      "Feature file for NALYS exists\n",
      "Feature file for NALYS exists\n",
      "Feature file for NALYS exists\n",
      "Extract features from raw video for 0BX9N\n",
      "Feature file for 0BX9N exists\n",
      "Feature file for 0BX9N exists\n",
      "Feature file for 0BX9N exists\n",
      "Feature file for 0BX9N exists\n",
      "Extract features from raw video for JIOD0\n",
      "Extract features from raw video for GZMJK\n",
      "Feature file for GZMJK exists\n",
      "Extract features from raw video for CW4AU\n",
      "Feature file for CW4AU exists\n",
      "Feature file for CW4AU exists\n",
      "Feature file for CW4AU exists\n",
      "Extract features from raw video for KC863\n",
      "Extract features from raw video for TPHRR\n",
      "Feature file for TPHRR exists\n",
      "Feature file for TPHRR exists\n",
      "Extract features from raw video for TW3RS\n",
      "Extract features from raw video for 19ZJB\n",
      "Feature file for 19ZJB exists\n",
      "Extract features from raw video for E1VFZ\n",
      "Extract features from raw video for VCU4P\n",
      "Feature file for VCU4P exists\n",
      "Extract features from raw video for OMFOJ\n",
      "Feature file for OMFOJ exists\n",
      "Extract features from raw video for 8JT6S\n",
      "Extract features from raw video for 0YOXV\n",
      "Feature file for 0YOXV exists\n",
      "Feature file for 0YOXV exists\n",
      "Extract features from raw video for HSH5R\n",
      "Feature file for HSH5R exists\n",
      "Extract features from raw video for LZEWE\n",
      "Feature file for LZEWE exists\n",
      "Extract features from raw video for 2JR26\n",
      "Extract features from raw video for 1TW98\n",
      "Extract features from raw video for X8A6H\n",
      "Feature file for X8A6H exists\n",
      "Extract features from raw video for 8Y7P5\n",
      "Feature file for 8Y7P5 exists\n",
      "Extract features from raw video for WPZQ7\n",
      "Feature file for WPZQ7 exists\n",
      "Extract features from raw video for XF93D\n",
      "Feature file for XF93D exists\n",
      "Feature file for XF93D exists\n",
      "Feature file for XF93D exists\n",
      "Extract features from raw video for Y9JWG\n",
      "Feature file for Y9JWG exists\n",
      "Extract features from raw video for GK15U\n",
      "Feature file for GK15U exists\n",
      "Feature file for GK15U exists\n",
      "Extract features from raw video for LFU36\n",
      "Feature file for LFU36 exists\n",
      "Feature file for LFU36 exists\n",
      "Extract features from raw video for VTEWM\n",
      "Feature file for VTEWM exists\n",
      "Extract features from raw video for P3EW1\n",
      "Extract features from raw video for SSP8C\n",
      "Extract features from raw video for J1YJ6\n",
      "Feature file for J1YJ6 exists\n",
      "Feature file for J1YJ6 exists\n",
      "Extract features from raw video for TD6CM\n",
      "Extract features from raw video for ZCULX\n",
      "Feature file for ZCULX exists\n",
      "Feature file for ZCULX exists\n",
      "Extract features from raw video for 9X208\n",
      "Feature file for 9X208 exists\n",
      "Feature file for 9X208 exists\n",
      "Feature file for 9X208 exists\n",
      "Feature file for 9X208 exists\n",
      "Extract features from raw video for 7VSIV\n",
      "Feature file for 7VSIV exists\n",
      "Extract features from raw video for EJJIO\n",
      "Feature file for EJJIO exists\n",
      "Feature file for EJJIO exists\n",
      "Extract features from raw video for NOLQ7\n",
      "Feature file for NOLQ7 exists\n",
      "Extract features from raw video for YMM1Z\n",
      "Extract features from raw video for ZKOCS\n",
      "Feature file for ZKOCS exists\n",
      "Feature file for ZKOCS exists\n",
      "Extract features from raw video for VY1GQ\n",
      "Feature file for VY1GQ exists\n",
      "Feature file for VY1GQ exists\n",
      "Feature file for VY1GQ exists\n",
      "Extract features from raw video for 6U082\n",
      "Feature file for 6U082 exists\n",
      "Extract features from raw video for PIMO4\n",
      "Feature file for PIMO4 exists\n",
      "Extract features from raw video for Q9H04\n",
      "Feature file for Q9H04 exists\n",
      "Feature file for Q9H04 exists\n",
      "Feature file for Q9H04 exists\n",
      "Feature file for Q9H04 exists\n",
      "Feature file for Q9H04 exists\n",
      "Extract features from raw video for WFUK2\n",
      "Extract features from raw video for WR2Q2\n",
      "Extract features from raw video for GC1Q1\n",
      "Feature file for GC1Q1 exists\n",
      "Extract features from raw video for O45BC\n",
      "Feature file for O45BC exists\n",
      "Feature file for O45BC exists\n",
      "Extract features from raw video for FEWUR\n",
      "Feature file for FEWUR exists\n",
      "Extract features from raw video for 1U9TF\n",
      "Feature file for 1U9TF exists\n",
      "Extract features from raw video for IZZ3Y\n",
      "Feature file for IZZ3Y exists\n",
      "Feature file for IZZ3Y exists\n",
      "Feature file for IZZ3Y exists\n",
      "Feature file for IZZ3Y exists\n",
      "Extract features from raw video for U5B14\n",
      "Feature file for U5B14 exists\n",
      "Extract features from raw video for WZ351\n",
      "Extract features from raw video for U03TA\n",
      "Feature file for U03TA exists\n",
      "Extract features from raw video for JQHIC\n",
      "Feature file for JQHIC exists\n",
      "Extract features from raw video for ZDX0Y\n",
      "Feature file for ZDX0Y exists\n",
      "Extract features from raw video for XYGU1\n",
      "Feature file for XYGU1 exists\n",
      "Feature file for XYGU1 exists\n",
      "Feature file for XYGU1 exists\n",
      "Extract features from raw video for Q9TIN\n",
      "Extract features from raw video for IZCB0\n",
      "Feature file for IZCB0 exists\n",
      "Extract features from raw video for YL612\n",
      "Feature file for YL612 exists\n",
      "Extract features from raw video for DU7H1\n",
      "Feature file for DU7H1 exists\n",
      "Feature file for DU7H1 exists\n",
      "Extract features from raw video for 39LQ8\n",
      "Feature file for 39LQ8 exists\n",
      "Feature file for 39LQ8 exists\n",
      "Extract features from raw video for GU43L\n",
      "Extract features from raw video for SLMQF\n",
      "Feature file for SLMQF exists\n",
      "Feature file for SLMQF exists\n",
      "Feature file for SLMQF exists\n",
      "Feature file for SLMQF exists\n",
      "Feature file for SLMQF exists\n",
      "Extract features from raw video for U3NKR\n",
      "Extract features from raw video for TLSUX\n",
      "Feature file for TLSUX exists\n",
      "Extract features from raw video for GVX7E\n",
      "Extract features from raw video for WV9FZ\n",
      "Feature file for WV9FZ exists\n",
      "Feature file for WV9FZ exists\n",
      "Extract features from raw video for 6KDQO\n",
      "Feature file for 6KDQO exists\n",
      "Extract features from raw video for S2EXT\n",
      "Extract features from raw video for RRDAM\n",
      "Feature file for RRDAM exists\n",
      "Feature file for RRDAM exists\n",
      "Feature file for RRDAM exists\n",
      "Feature file for RRDAM exists\n",
      "Extract features from raw video for 41CZS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature file for 41CZS exists\n",
      "Feature file for 41CZS exists\n",
      "Extract features from raw video for V34GF\n",
      "Feature file for V34GF exists\n",
      "Extract features from raw video for 01KML\n",
      "Extract features from raw video for FERH5\n",
      "Feature file for FERH5 exists\n",
      "Feature file for FERH5 exists\n",
      "Feature file for FERH5 exists\n",
      "Extract features from raw video for NOJK1\n",
      "Feature file for NOJK1 exists\n",
      "Feature file for NOJK1 exists\n",
      "Feature file for NOJK1 exists\n",
      "Extract features from raw video for V3RAX\n",
      "Feature file for V3RAX exists\n",
      "Feature file for V3RAX exists\n",
      "Feature file for V3RAX exists\n",
      "Extract features from raw video for QNKDI\n",
      "Feature file for QNKDI exists\n",
      "Extract features from raw video for GIC6A\n",
      "Feature file for GIC6A exists\n",
      "Feature file for GIC6A exists\n",
      "Extract features from raw video for NCDE3\n",
      "Feature file for NCDE3 exists\n",
      "Feature file for NCDE3 exists\n",
      "Extract features from raw video for UB3KO\n",
      "Feature file for UB3KO exists\n",
      "Feature file for UB3KO exists\n",
      "Extract features from raw video for FIV2P\n",
      "Extract features from raw video for AGELP\n",
      "Feature file for AGELP exists\n",
      "Feature file for AGELP exists\n",
      "Feature file for AGELP exists\n",
      "Extract features from raw video for X29NF\n",
      "Feature file for X29NF exists\n",
      "Extract features from raw video for XHGV7\n",
      "Extract features from raw video for X89FW\n",
      "Feature file for X89FW exists\n",
      "Feature file for X89FW exists\n",
      "Feature file for X89FW exists\n",
      "Extract features from raw video for A4SR3\n",
      "Extract features from raw video for N7ZBM\n",
      "Feature file for N7ZBM exists\n",
      "Extract features from raw video for 56XKK\n",
      "Feature file for 56XKK exists\n",
      "Extract features from raw video for EIB97\n",
      "Feature file for EIB97 exists\n",
      "Feature file for EIB97 exists\n",
      "Extract features from raw video for ZXHLY\n",
      "Feature file for ZXHLY exists\n",
      "Extract features from raw video for P9D7P\n",
      "Feature file for P9D7P exists\n",
      "Extract features from raw video for B6S6T\n",
      "Feature file for B6S6T exists\n",
      "Feature file for B6S6T exists\n",
      "Extract features from raw video for GFFJM\n",
      "Feature file for GFFJM exists\n",
      "Extract features from raw video for WBATR\n",
      "Feature file for WBATR exists\n",
      "Feature file for WBATR exists\n",
      "Feature file for WBATR exists\n",
      "Extract features from raw video for DAS12\n",
      "Feature file for DAS12 exists\n",
      "Feature file for DAS12 exists\n",
      "Feature file for DAS12 exists\n",
      "Extract features from raw video for MUK89\n",
      "Extract features from raw video for W2LM5\n",
      "Feature file for W2LM5 exists\n",
      "Extract features from raw video for JJON5\n",
      "Feature file for JJON5 exists\n",
      "Extract features from raw video for 73X8Q\n",
      "Feature file for 73X8Q exists\n",
      "Feature file for 73X8Q exists\n",
      "Feature file for 73X8Q exists\n",
      "Extract features from raw video for O5N93\n",
      "Feature file for O5N93 exists\n",
      "Extract features from raw video for NDX21\n",
      "Extract features from raw video for U0ACD\n",
      "Extract features from raw video for WPR8G\n",
      "Feature file for WPR8G exists\n",
      "Extract features from raw video for 869NM\n",
      "Feature file for 869NM exists\n",
      "Extract features from raw video for 99SGB\n",
      "Extract features from raw video for 9R4AQ\n",
      "Feature file for 9R4AQ exists\n",
      "Extract features from raw video for N00HR\n",
      "Feature file for N00HR exists\n",
      "Feature file for N00HR exists\n",
      "Feature file for N00HR exists\n",
      "Feature file for N00HR exists\n",
      "Extract features from raw video for WIOCA\n",
      "Feature file for WIOCA exists\n",
      "Extract features from raw video for S7RXC\n",
      "Feature file for S7RXC exists\n",
      "Feature file for S7RXC exists\n",
      "Extract features from raw video for 7HWK2\n",
      "Feature file for 7HWK2 exists\n",
      "Feature file for 7HWK2 exists\n",
      "Feature file for 7HWK2 exists\n",
      "Feature file for 7HWK2 exists\n",
      "Feature file for 7HWK2 exists\n",
      "Extract features from raw video for WZA37\n",
      "Feature file for WZA37 exists\n",
      "Extract features from raw video for NK9RX\n",
      "Feature file for NK9RX exists\n",
      "Feature file for NK9RX exists\n",
      "Feature file for NK9RX exists\n",
      "Extract features from raw video for 9RA4P\n",
      "Extract features from raw video for 78FJX\n",
      "Feature file for 78FJX exists\n",
      "Feature file for 78FJX exists\n",
      "Feature file for 78FJX exists\n",
      "Extract features from raw video for Z1LVD\n",
      "Feature file for Z1LVD exists\n",
      "Feature file for Z1LVD exists\n",
      "Feature file for Z1LVD exists\n",
      "Feature file for Z1LVD exists\n",
      "Extract features from raw video for V4YCA\n",
      "Feature file for V4YCA exists\n",
      "Extract features from raw video for RRZU3\n",
      "Feature file for RRZU3 exists\n",
      "Feature file for RRZU3 exists\n",
      "Feature file for RRZU3 exists\n",
      "Extract features from raw video for 5ZGRN\n",
      "Feature file for 5ZGRN exists\n",
      "Feature file for 5ZGRN exists\n",
      "Extract features from raw video for NGXV2\n",
      "Feature file for NGXV2 exists\n",
      "Extract features from raw video for 5C837\n",
      "Feature file for 5C837 exists\n",
      "Extract features from raw video for G4MDY\n",
      "Feature file for G4MDY exists\n",
      "Feature file for G4MDY exists\n",
      "Extract features from raw video for 9LONJ\n",
      "Feature file for 9LONJ exists\n",
      "Extract features from raw video for JYC6G\n",
      "Extract features from raw video for LK1AE\n",
      "Feature file for LK1AE exists\n",
      "Extract features from raw video for 13MWT\n",
      "Feature file for 13MWT exists\n",
      "Extract features from raw video for IACBH\n",
      "Feature file for IACBH exists\n",
      "Extract features from raw video for 7JTEK\n",
      "Extract features from raw video for 9UDMH\n",
      "Extract features from raw video for VE5DN\n",
      "Feature file for VE5DN exists\n",
      "Feature file for VE5DN exists\n",
      "Feature file for VE5DN exists\n",
      "Feature file for VE5DN exists\n",
      "Extract features from raw video for W74ZY\n",
      "Feature file for W74ZY exists\n",
      "Extract features from raw video for 6E6GF\n",
      "Feature file for 6E6GF exists\n",
      "Feature file for 6E6GF exists\n",
      "Feature file for 6E6GF exists\n",
      "Feature file for 6E6GF exists\n",
      "Extract features from raw video for 14TJT\n",
      "Extract features from raw video for 8GP10\n",
      "Extract features from raw video for OD1A5\n",
      "Feature file for OD1A5 exists\n",
      "Feature file for OD1A5 exists\n",
      "Feature file for OD1A5 exists\n",
      "Feature file for OD1A5 exists\n",
      "Feature file for OD1A5 exists\n",
      "Feature file for OD1A5 exists\n",
      "Extract features from raw video for PQBGG\n",
      "Feature file for PQBGG exists\n",
      "Feature file for PQBGG exists\n",
      "Extract features from raw video for 7JSAI\n",
      "Feature file for 7JSAI exists\n",
      "Extract features from raw video for KJK56\n",
      "Feature file for KJK56 exists\n",
      "Extract features from raw video for XP305\n",
      "Feature file for XP305 exists\n",
      "Feature file for XP305 exists\n",
      "Feature file for XP305 exists\n",
      "Extract features from raw video for IZTHW\n",
      "Extract features from raw video for IGVLE\n",
      "Feature file for IGVLE exists\n",
      "Feature file for IGVLE exists\n",
      "Extract features from raw video for VAIVN\n",
      "Feature file for VAIVN exists\n",
      "Feature file for VAIVN exists\n",
      "Extract features from raw video for K6DF2\n",
      "Feature file for K6DF2 exists\n",
      "Feature file for K6DF2 exists\n",
      "Feature file for K6DF2 exists\n",
      "Feature file for K6DF2 exists\n",
      "Feature file for K6DF2 exists\n",
      "Extract features from raw video for DY9AE\n",
      "Feature file for DY9AE exists\n",
      "Extract features from raw video for BOKLM\n",
      "Feature file for BOKLM exists\n",
      "Feature file for BOKLM exists\n",
      "Extract features from raw video for Q166J\n",
      "Extract features from raw video for A7OCU\n",
      "Feature file for A7OCU exists\n",
      "Extract features from raw video for D32A4\n",
      "Feature file for D32A4 exists\n",
      "Extract features from raw video for M91YM\n",
      "Feature file for M91YM exists\n",
      "Feature file for M91YM exists\n",
      "Extract features from raw video for YPIKO\n",
      "Feature file for YPIKO exists\n",
      "Feature file for YPIKO exists\n",
      "Feature file for YPIKO exists\n",
      "Extract features from raw video for VCV6A\n",
      "Feature file for VCV6A exists\n",
      "Feature file for VCV6A exists\n",
      "Feature file for VCV6A exists\n",
      "Feature file for VCV6A exists\n",
      "Extract features from raw video for RTXE6\n",
      "Feature file for RTXE6 exists\n",
      "Extract features from raw video for DPDER\n",
      "Feature file for DPDER exists\n",
      "Feature file for DPDER exists\n",
      "Extract features from raw video for 5GITI\n",
      "Extract features from raw video for F8UU2\n",
      "Feature file for F8UU2 exists\n",
      "Extract features from raw video for H94MQ\n",
      "Feature file for H94MQ exists\n",
      "Extract features from raw video for C4MP2\n",
      "Extract features from raw video for 2K755\n",
      "Feature file for 2K755 exists\n",
      "Extract features from raw video for 5H1P1\n",
      "Feature file for 5H1P1 exists\n",
      "Extract features from raw video for NOFSE\n",
      "Feature file for NOFSE exists\n",
      "Extract features from raw video for WJFGC\n",
      "Feature file for WJFGC exists\n",
      "Extract features from raw video for YBO6N\n",
      "Feature file for YBO6N exists\n",
      "Extract features from raw video for 7W66P\n",
      "Feature file for 7W66P exists\n",
      "Feature file for 7W66P exists\n",
      "Feature file for 7W66P exists\n",
      "Feature file for 7W66P exists\n",
      "Extract features from raw video for N79WJ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract features from raw video for 6JKD6\n",
      "Feature file for 6JKD6 exists\n",
      "Feature file for 6JKD6 exists\n",
      "Feature file for 6JKD6 exists\n",
      "Extract features from raw video for Q4TKG\n",
      "Feature file for Q4TKG exists\n",
      "Extract features from raw video for DJG7A\n",
      "Extract features from raw video for Q5ZIL\n",
      "Feature file for Q5ZIL exists\n",
      "Feature file for Q5ZIL exists\n",
      "Extract features from raw video for 8VSV6\n",
      "Extract features from raw video for EHYXP\n",
      "Extract features from raw video for C9VPX\n",
      "Feature file for C9VPX exists\n",
      "Extract features from raw video for 5AR9B\n",
      "Feature file for 5AR9B exists\n",
      "Extract features from raw video for F082Z\n",
      "Extract features from raw video for 1JGRO\n",
      "Extract features from raw video for 81YUE\n",
      "Feature file for 81YUE exists\n",
      "Feature file for 81YUE exists\n",
      "Extract features from raw video for WE2PF\n",
      "Feature file for WE2PF exists\n",
      "Extract features from raw video for EG1XK\n",
      "Feature file for EG1XK exists\n",
      "Feature file for EG1XK exists\n",
      "Feature file for EG1XK exists\n",
      "Extract features from raw video for 7XR13\n",
      "Extract features from raw video for XSS0J\n",
      "Feature file for XSS0J exists\n",
      "Extract features from raw video for P8UT3\n",
      "Feature file for P8UT3 exists\n",
      "Extract features from raw video for OLEWM\n",
      "Feature file for OLEWM exists\n",
      "Extract features from raw video for 5U70R\n",
      "Feature file for 5U70R exists\n",
      "Extract features from raw video for HKJUR\n",
      "Feature file for HKJUR exists\n",
      "Extract features from raw video for YQCYJ\n",
      "Extract features from raw video for CK3H7\n",
      "Extract features from raw video for X3KFE\n",
      "Feature file for X3KFE exists\n",
      "Feature file for X3KFE exists\n",
      "Feature file for X3KFE exists\n",
      "Feature file for X3KFE exists\n",
      "Extract features from raw video for PFCRB\n",
      "Feature file for PFCRB exists\n",
      "Feature file for PFCRB exists\n",
      "Extract features from raw video for 4CHXK\n",
      "Feature file for 4CHXK exists\n",
      "Extract features from raw video for 4QSRS\n",
      "Feature file for 4QSRS exists\n",
      "Feature file for 4QSRS exists\n",
      "Extract features from raw video for PW3GG\n",
      "Extract features from raw video for 27SS2\n",
      "Feature file for 27SS2 exists\n",
      "Extract features from raw video for 7OXNH\n",
      "Extract features from raw video for YKT8I\n",
      "Feature file for YKT8I exists\n",
      "Extract features from raw video for 82ZNR\n",
      "Extract features from raw video for KFI7N\n",
      "Feature file for KFI7N exists\n",
      "Feature file for KFI7N exists\n",
      "Extract features from raw video for EWY6I\n",
      "Extract features from raw video for AAS9S\n",
      "Feature file for AAS9S exists\n",
      "Extract features from raw video for O1ILB\n",
      "Feature file for O1ILB exists\n",
      "Feature file for O1ILB exists\n",
      "Feature file for O1ILB exists\n",
      "Extract features from raw video for 8M0ZV\n",
      "Feature file for 8M0ZV exists\n",
      "Extract features from raw video for 94KP4\n",
      "Feature file for 94KP4 exists\n",
      "Feature file for 94KP4 exists\n",
      "Extract features from raw video for FQDD1\n",
      "Feature file for FQDD1 exists\n",
      "Extract features from raw video for HB4AB\n",
      "Feature file for HB4AB exists\n",
      "Extract features from raw video for 0FO58\n",
      "Feature file for 0FO58 exists\n",
      "Feature file for 0FO58 exists\n",
      "Extract features from raw video for 9335E\n",
      "Feature file for 9335E exists\n",
      "Feature file for 9335E exists\n",
      "Feature file for 9335E exists\n",
      "Feature file for 9335E exists\n",
      "Feature file for 9335E exists\n",
      "Feature file for 9335E exists\n",
      "Extract features from raw video for 6KUUU\n",
      "Feature file for 6KUUU exists\n",
      "Extract features from raw video for QH3FK\n",
      "Extract features from raw video for N9D4C\n",
      "Feature file for N9D4C exists\n",
      "Extract features from raw video for QYSER\n",
      "Feature file for QYSER exists\n",
      "Extract features from raw video for 5CT0V\n",
      "Extract features from raw video for AIT3V\n",
      "Extract features from raw video for R1OUC\n",
      "Feature file for R1OUC exists\n",
      "Extract features from raw video for OZIJ7\n",
      "Feature file for OZIJ7 exists\n",
      "Extract features from raw video for TDNV3\n",
      "Extract features from raw video for RJIEO\n",
      "Extract features from raw video for 83J53\n",
      "Extract features from raw video for BKEYX\n",
      "Feature file for BKEYX exists\n",
      "Extract features from raw video for RO8N5\n",
      "Extract features from raw video for AEJ4T\n",
      "Extract features from raw video for 201W8\n",
      "Feature file for 201W8 exists\n",
      "Feature file for 201W8 exists\n",
      "Extract features from raw video for OXUKR\n",
      "Feature file for OXUKR exists\n",
      "Feature file for OXUKR exists\n",
      "Extract features from raw video for ZSHV8\n",
      "Feature file for ZSHV8 exists\n",
      "Extract features from raw video for IXY95\n",
      "Feature file for IXY95 exists\n",
      "Extract features from raw video for 1X765\n",
      "Feature file for 1X765 exists\n",
      "Extract features from raw video for JLQLC\n",
      "Feature file for JLQLC exists\n",
      "Extract features from raw video for DHFA6\n",
      "Feature file for DHFA6 exists\n",
      "Feature file for DHFA6 exists\n",
      "Extract features from raw video for URG8B\n",
      "Feature file for URG8B exists\n",
      "Feature file for URG8B exists\n",
      "Extract features from raw video for 0CGMQ\n",
      "Extract features from raw video for T35WB\n",
      "Extract features from raw video for 48IQL\n",
      "Feature file for 48IQL exists\n",
      "Feature file for 48IQL exists\n",
      "Extract features from raw video for 3KZF7\n",
      "Feature file for 3KZF7 exists\n",
      "Extract features from raw video for DHR5F\n",
      "Feature file for DHR5F exists\n",
      "Feature file for DHR5F exists\n",
      "Feature file for DHR5F exists\n",
      "Feature file for DHR5F exists\n",
      "Extract features from raw video for VP3WN\n",
      "Extract features from raw video for V10LX\n",
      "Feature file for V10LX exists\n",
      "Feature file for V10LX exists\n",
      "Extract features from raw video for 38QA4\n",
      "Feature file for 38QA4 exists\n",
      "Feature file for 38QA4 exists\n",
      "Feature file for 38QA4 exists\n",
      "Feature file for 38QA4 exists\n",
      "Extract features from raw video for TC3BF\n",
      "Extract features from raw video for HWL2J\n",
      "Extract features from raw video for 9HI9D\n",
      "Feature file for 9HI9D exists\n",
      "Feature file for 9HI9D exists\n",
      "Feature file for 9HI9D exists\n",
      "Extract features from raw video for PRQSR\n",
      "Feature file for PRQSR exists\n",
      "Feature file for PRQSR exists\n",
      "Extract features from raw video for GD9BQ\n",
      "Feature file for GD9BQ exists\n",
      "Extract features from raw video for 3OQ8M\n",
      "Feature file for 3OQ8M exists\n",
      "Extract features from raw video for VX7P0\n",
      "Feature file for VX7P0 exists\n",
      "Extract features from raw video for GX4B1\n",
      "Extract features from raw video for 170OQ\n",
      "Extract features from raw video for P3XT7\n",
      "Feature file for P3XT7 exists\n",
      "Extract features from raw video for X0JKJ\n",
      "Feature file for X0JKJ exists\n",
      "Extract features from raw video for XAX61\n",
      "Extract features from raw video for XFS7Z\n",
      "Feature file for XFS7Z exists\n",
      "Extract features from raw video for IJ587\n",
      "Extract features from raw video for C41G7\n",
      "Extract features from raw video for KBPI3\n",
      "Extract features from raw video for 6YZOL\n",
      "Feature file for 6YZOL exists\n",
      "Extract features from raw video for ESM8H\n",
      "Feature file for ESM8H exists\n",
      "Extract features from raw video for 7E6AB\n",
      "Feature file for 7E6AB exists\n",
      "Extract features from raw video for 1W28T\n",
      "Feature file for 1W28T exists\n",
      "Feature file for 1W28T exists\n",
      "Extract features from raw video for 0RJKT\n",
      "Extract features from raw video for AZTTC\n",
      "Feature file for AZTTC exists\n",
      "Feature file for AZTTC exists\n",
      "Feature file for AZTTC exists\n",
      "Feature file for AZTTC exists\n",
      "Feature file for AZTTC exists\n",
      "Feature file for AZTTC exists\n",
      "Extract features from raw video for ISHJ4\n",
      "Feature file for ISHJ4 exists\n",
      "Extract features from raw video for QI3JB\n",
      "Extract features from raw video for MC50M\n",
      "Extract features from raw video for URWJL\n",
      "Feature file for URWJL exists\n",
      "Feature file for URWJL exists\n",
      "Extract features from raw video for I4K7B\n",
      "Feature file for I4K7B exists\n",
      "Extract features from raw video for N9TRF\n",
      "Feature file for N9TRF exists\n",
      "Extract features from raw video for 5JIGM\n",
      "Feature file for 5JIGM exists\n",
      "Extract features from raw video for Y6419\n",
      "Extract features from raw video for 4HGD7\n",
      "Feature file for 4HGD7 exists\n",
      "Feature file for 4HGD7 exists\n",
      "Extract features from raw video for DLBRW\n",
      "Feature file for DLBRW exists\n",
      "Extract features from raw video for QO6RV\n",
      "Feature file for QO6RV exists\n",
      "Feature file for QO6RV exists\n",
      "Feature file for QO6RV exists\n",
      "Feature file for QO6RV exists\n",
      "Extract features from raw video for 4WUNC\n",
      "Feature file for 4WUNC exists\n",
      "Feature file for 4WUNC exists\n",
      "Feature file for 4WUNC exists\n",
      "Feature file for 4WUNC exists\n",
      "Extract features from raw video for ZX1R7\n",
      "Extract features from raw video for CVPQR\n",
      "Extract features from raw video for 44Y6S\n",
      "Feature file for 44Y6S exists\n",
      "Extract features from raw video for UCFCB\n",
      "Feature file for UCFCB exists\n",
      "Feature file for UCFCB exists\n",
      "Extract features from raw video for K21RO\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature file for K21RO exists\n",
      "Feature file for K21RO exists\n",
      "Extract features from raw video for GRJG1\n",
      "Extract features from raw video for CCCUJ\n",
      "Feature file for CCCUJ exists\n",
      "Feature file for CCCUJ exists\n",
      "Feature file for CCCUJ exists\n",
      "Extract features from raw video for 29C6X\n",
      "Extract features from raw video for LKSBL\n",
      "Feature file for LKSBL exists\n",
      "Feature file for LKSBL exists\n",
      "Feature file for LKSBL exists\n",
      "Extract features from raw video for 3GY40\n",
      "Feature file for 3GY40 exists\n",
      "Feature file for 3GY40 exists\n",
      "Feature file for 3GY40 exists\n",
      "Extract features from raw video for UR7C8\n",
      "Feature file for UR7C8 exists\n",
      "Feature file for UR7C8 exists\n",
      "Extract features from raw video for 8Y4YD\n",
      "Extract features from raw video for 1TWH6\n",
      "Feature file for 1TWH6 exists\n",
      "Feature file for 1TWH6 exists\n",
      "Feature file for 1TWH6 exists\n",
      "Feature file for 1TWH6 exists\n",
      "Extract features from raw video for 28D7L\n",
      "Feature file for 28D7L exists\n",
      "Extract features from raw video for 4X2JC\n",
      "Feature file for 4X2JC exists\n",
      "Extract features from raw video for 129SP\n",
      "Feature file for 129SP exists\n",
      "Extract features from raw video for 5R83A\n",
      "Feature file for 5R83A exists\n",
      "Feature file for 5R83A exists\n",
      "Extract features from raw video for ZWY3E\n",
      "Feature file for ZWY3E exists\n",
      "Feature file for ZWY3E exists\n",
      "Extract features from raw video for AYXFY\n",
      "Feature file for AYXFY exists\n",
      "Extract features from raw video for STDCJ\n",
      "Feature file for STDCJ exists\n",
      "Feature file for STDCJ exists\n",
      "Extract features from raw video for L57L2\n",
      "Feature file for L57L2 exists\n",
      "Feature file for L57L2 exists\n",
      "Extract features from raw video for IQM7A\n",
      "Feature file for IQM7A exists\n",
      "Feature file for IQM7A exists\n",
      "Extract features from raw video for X7R9N\n",
      "Extract features from raw video for 8ZF5S\n",
      "Extract features from raw video for YX3W8\n",
      "Extract features from raw video for SQYTO\n",
      "Feature file for SQYTO exists\n",
      "Feature file for SQYTO exists\n",
      "Feature file for SQYTO exists\n",
      "Feature file for SQYTO exists\n",
      "Feature file for SQYTO exists\n",
      "Extract features from raw video for 8V9IX\n",
      "Extract features from raw video for N8WK8\n",
      "Extract features from raw video for AVA41\n",
      "Feature file for AVA41 exists\n",
      "Feature file for AVA41 exists\n",
      "Feature file for AVA41 exists\n",
      "Extract features from raw video for STYTN\n",
      "Feature file for STYTN exists\n",
      "Feature file for STYTN exists\n",
      "Feature file for STYTN exists\n",
      "Extract features from raw video for 9KGIR\n",
      "Feature file for 9KGIR exists\n",
      "Extract features from raw video for R5L98\n",
      "Extract features from raw video for 6JGXL\n",
      "Extract features from raw video for Q3UAN\n",
      "Feature file for Q3UAN exists\n",
      "Feature file for Q3UAN exists\n",
      "Extract features from raw video for 463UL\n",
      "Extract features from raw video for AWITI\n",
      "Feature file for AWITI exists\n",
      "Feature file for AWITI exists\n",
      "Feature file for AWITI exists\n",
      "Extract features from raw video for 1O6PH\n",
      "Feature file for 1O6PH exists\n",
      "Feature file for 1O6PH exists\n",
      "Feature file for 1O6PH exists\n",
      "Extract features from raw video for XBRO4\n",
      "Feature file for XBRO4 exists\n",
      "Extract features from raw video for 7QWL3\n",
      "Feature file for 7QWL3 exists\n",
      "Feature file for 7QWL3 exists\n",
      "Feature file for 7QWL3 exists\n",
      "Feature file for 7QWL3 exists\n",
      "Extract features from raw video for Q57HC\n",
      "Feature file for Q57HC exists\n",
      "Extract features from raw video for 79YH2\n",
      "Extract features from raw video for G3OUM\n",
      "Feature file for G3OUM exists\n",
      "Feature file for G3OUM exists\n",
      "Feature file for G3OUM exists\n",
      "Extract features from raw video for P2UBC\n",
      "Feature file for P2UBC exists\n",
      "Feature file for P2UBC exists\n",
      "Feature file for P2UBC exists\n",
      "Feature file for P2UBC exists\n",
      "Extract features from raw video for GN4SJ\n",
      "Feature file for GN4SJ exists\n",
      "Feature file for GN4SJ exists\n",
      "Feature file for GN4SJ exists\n",
      "Feature file for GN4SJ exists\n",
      "Feature file for GN4SJ exists\n",
      "Extract features from raw video for 6MUM6\n",
      "Extract features from raw video for D19IR\n",
      "Extract features from raw video for YQSN8\n",
      "Feature file for YQSN8 exists\n",
      "Feature file for YQSN8 exists\n",
      "Extract features from raw video for 5K0KJ\n",
      "Extract features from raw video for 1DNAX\n",
      "Feature file for 1DNAX exists\n",
      "Feature file for 1DNAX exists\n",
      "Feature file for 1DNAX exists\n",
      "Feature file for 1DNAX exists\n",
      "Extract features from raw video for O76N2\n",
      "Feature file for O76N2 exists\n",
      "Extract features from raw video for 8BCI8\n",
      "Feature file for 8BCI8 exists\n",
      "Feature file for 8BCI8 exists\n",
      "Extract features from raw video for 36VYU\n",
      "Extract features from raw video for ZD3GI\n",
      "Feature file for ZD3GI exists\n",
      "Feature file for ZD3GI exists\n",
      "Feature file for ZD3GI exists\n",
      "Extract features from raw video for OB9H3\n",
      "Extract features from raw video for 30LGT\n",
      "Feature file for 30LGT exists\n",
      "Extract features from raw video for UX8NQ\n",
      "Feature file for UX8NQ exists\n",
      "Feature file for UX8NQ exists\n",
      "Extract features from raw video for BQAUC\n",
      "Feature file for BQAUC exists\n",
      "Feature file for BQAUC exists\n",
      "Extract features from raw video for VLZ40\n",
      "Extract features from raw video for S47DI\n",
      "Extract features from raw video for RH2YW\n",
      "Feature file for RH2YW exists\n",
      "Feature file for RH2YW exists\n",
      "Extract features from raw video for ZAJAJ\n",
      "Feature file for ZAJAJ exists\n",
      "Extract features from raw video for IGOQK\n",
      "Extract features from raw video for OZCGO\n",
      "Extract features from raw video for OVHFT\n",
      "Feature file for OVHFT exists\n",
      "Extract features from raw video for WYYUD\n",
      "Feature file for WYYUD exists\n",
      "Feature file for WYYUD exists\n",
      "Feature file for WYYUD exists\n",
      "Extract features from raw video for 706BT\n",
      "Feature file for 706BT exists\n",
      "Extract features from raw video for U45LK\n",
      "Feature file for U45LK exists\n",
      "Extract features from raw video for 2Q5Y2\n",
      "Feature file for 2Q5Y2 exists\n",
      "Extract features from raw video for QOWXK\n",
      "Feature file for QOWXK exists\n",
      "Extract features from raw video for RBNLA\n",
      "Feature file for RBNLA exists\n",
      "Extract features from raw video for D0YWV\n",
      "Feature file for D0YWV exists\n",
      "Extract features from raw video for 7R8ZU\n",
      "Extract features from raw video for 9B93K\n",
      "Feature file for 9B93K exists\n",
      "Feature file for 9B93K exists\n",
      "Extract features from raw video for NTYC3\n",
      "Feature file for NTYC3 exists\n",
      "Feature file for NTYC3 exists\n",
      "Feature file for NTYC3 exists\n",
      "Extract features from raw video for WOOYQ\n",
      "Feature file for WOOYQ exists\n",
      "Extract features from raw video for RUOOY\n",
      "Feature file for RUOOY exists\n",
      "Extract features from raw video for E9EKR\n",
      "Feature file for E9EKR exists\n",
      "Extract features from raw video for XAOUP\n",
      "Extract features from raw video for J3V1D\n",
      "Extract features from raw video for TSBB8\n",
      "Extract features from raw video for E2Q68\n",
      "Extract features from raw video for O6V4U\n",
      "Feature file for O6V4U exists\n",
      "Feature file for O6V4U exists\n",
      "Feature file for O6V4U exists\n",
      "Extract features from raw video for OOWJ9\n",
      "Feature file for OOWJ9 exists\n",
      "Feature file for OOWJ9 exists\n",
      "Feature file for OOWJ9 exists\n",
      "Extract features from raw video for 0MDYC\n",
      "Extract features from raw video for G81JB\n",
      "Feature file for G81JB exists\n",
      "Feature file for G81JB exists\n",
      "Extract features from raw video for 1YTD7\n",
      "Feature file for 1YTD7 exists\n",
      "Extract features from raw video for CMEA6\n",
      "Extract features from raw video for ZCH7N\n",
      "Feature file for ZCH7N exists\n",
      "Feature file for ZCH7N exists\n",
      "Feature file for ZCH7N exists\n",
      "Extract features from raw video for QLKSV\n",
      "Feature file for QLKSV exists\n",
      "Extract features from raw video for FUT86\n",
      "Feature file for FUT86 exists\n",
      "Extract features from raw video for RLS2I\n",
      "Extract features from raw video for UNOW9\n",
      "Feature file for UNOW9 exists\n",
      "Feature file for UNOW9 exists\n",
      "Extract features from raw video for MU54W\n",
      "Feature file for MU54W exists\n",
      "Feature file for MU54W exists\n",
      "Extract features from raw video for FDOY9\n",
      "Feature file for FDOY9 exists\n",
      "Feature file for FDOY9 exists\n",
      "Extract features from raw video for YMFWC\n",
      "Extract features from raw video for ZJ54N\n",
      "Extract features from raw video for QEZX9\n",
      "Extract features from raw video for 9Q1N7\n",
      "Feature file for 9Q1N7 exists\n",
      "Extract features from raw video for WKDPZ\n",
      "Extract features from raw video for 6FYXS\n",
      "Feature file for 6FYXS exists\n",
      "Feature file for 6FYXS exists\n",
      "Extract features from raw video for SQKR0\n",
      "Feature file for SQKR0 exists\n",
      "Feature file for SQKR0 exists\n",
      "Feature file for SQKR0 exists\n",
      "Feature file for SQKR0 exists\n",
      "Extract features from raw video for CDNNO\n",
      "Extract features from raw video for UPWM5\n",
      "Feature file for UPWM5 exists\n",
      "Extract features from raw video for TVS1P\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature file for TVS1P exists\n",
      "Extract features from raw video for VXRCZ\n",
      "Feature file for VXRCZ exists\n",
      "Feature file for VXRCZ exists\n",
      "Extract features from raw video for JUGS8\n",
      "Feature file for JUGS8 exists\n",
      "Feature file for JUGS8 exists\n",
      "Extract features from raw video for L62J5\n",
      "Extract features from raw video for PHIIX\n",
      "Extract features from raw video for ETAFB\n",
      "Extract features from raw video for 5AHQV\n",
      "Feature file for 5AHQV exists\n",
      "Feature file for 5AHQV exists\n",
      "Feature file for 5AHQV exists\n",
      "Extract features from raw video for OFNQV\n",
      "Extract features from raw video for DGSBQ\n",
      "Extract features from raw video for TYKVA\n",
      "Feature file for TYKVA exists\n",
      "Extract features from raw video for PZQIN\n",
      "Feature file for PZQIN exists\n",
      "Extract features from raw video for E7DKD\n",
      "Extract features from raw video for B53VP\n",
      "Feature file for B53VP exists\n",
      "Feature file for B53VP exists\n",
      "Extract features from raw video for H8QM1\n",
      "Extract features from raw video for HAR5P\n",
      "Feature file for HAR5P exists\n",
      "Feature file for HAR5P exists\n",
      "Feature file for HAR5P exists\n",
      "Extract features from raw video for T0PJG\n",
      "Feature file for T0PJG exists\n",
      "Feature file for T0PJG exists\n",
      "Feature file for T0PJG exists\n",
      "Feature file for T0PJG exists\n",
      "Feature file for T0PJG exists\n",
      "Extract features from raw video for V3CWF\n",
      "Feature file for V3CWF exists\n",
      "Extract features from raw video for RSRZ0\n",
      "Feature file for RSRZ0 exists\n",
      "Feature file for RSRZ0 exists\n",
      "Extract features from raw video for WZVHJ\n",
      "Feature file for WZVHJ exists\n",
      "Extract features from raw video for TEPWB\n",
      "Extract features from raw video for E6A0Y\n",
      "Extract features from raw video for DSXEN\n",
      "Feature file for DSXEN exists\n",
      "Feature file for DSXEN exists\n",
      "Extract features from raw video for RAQNI\n",
      "Feature file for RAQNI exists\n",
      "Feature file for RAQNI exists\n",
      "Feature file for RAQNI exists\n",
      "Extract features from raw video for RIUEI\n",
      "Feature file for RIUEI exists\n",
      "Feature file for RIUEI exists\n",
      "Feature file for RIUEI exists\n",
      "Extract features from raw video for 2I871\n",
      "Feature file for 2I871 exists\n",
      "Feature file for 2I871 exists\n",
      "Extract features from raw video for LSVHK\n",
      "Feature file for LSVHK exists\n",
      "Extract features from raw video for AXKNF\n",
      "Feature file for AXKNF exists\n",
      "Extract features from raw video for OM5R4\n",
      "Feature file for OM5R4 exists\n",
      "Extract features from raw video for DNXBJ\n",
      "Extract features from raw video for R5MFX\n",
      "Extract features from raw video for E3S4O\n",
      "Feature file for E3S4O exists\n",
      "Extract features from raw video for 3NE5P\n",
      "Feature file for 3NE5P exists\n",
      "Extract features from raw video for H1XBH\n",
      "Feature file for H1XBH exists\n",
      "Feature file for H1XBH exists\n",
      "Feature file for H1XBH exists\n",
      "Extract features from raw video for 5Y3VW\n",
      "Extract features from raw video for O8BH6\n",
      "Extract features from raw video for 3ZHEX\n",
      "Feature file for 3ZHEX exists\n",
      "Feature file for 3ZHEX exists\n",
      "Feature file for 3ZHEX exists\n",
      "Feature file for 3ZHEX exists\n",
      "Feature file for 3ZHEX exists\n",
      "Extract features from raw video for UG0TA\n",
      "Feature file for UG0TA exists\n",
      "Extract features from raw video for B4F0T\n",
      "Extract features from raw video for GYB9U\n",
      "Extract features from raw video for PW6CO\n",
      "Extract features from raw video for AXKNP\n",
      "Extract features from raw video for 2WGSN\n",
      "Feature file for 2WGSN exists\n",
      "Extract features from raw video for CPF9H\n",
      "Extract features from raw video for DQEC3\n",
      "Feature file for DQEC3 exists\n",
      "Feature file for DQEC3 exists\n",
      "Feature file for DQEC3 exists\n",
      "Feature file for DQEC3 exists\n",
      "Extract features from raw video for Y9SMX\n",
      "Feature file for Y9SMX exists\n",
      "Feature file for Y9SMX exists\n",
      "Feature file for Y9SMX exists\n",
      "Feature file for Y9SMX exists\n",
      "Extract features from raw video for CTOQR\n",
      "Feature file for CTOQR exists\n",
      "Feature file for CTOQR exists\n",
      "Extract features from raw video for NODDU\n",
      "Extract features from raw video for PXYN8\n",
      "Extract features from raw video for N67PL\n",
      "Feature file for N67PL exists\n",
      "Extract features from raw video for 71QKB\n",
      "Feature file for 71QKB exists\n",
      "Extract features from raw video for RYDUK\n",
      "Feature file for RYDUK exists\n",
      "Extract features from raw video for J39ZC\n",
      "Feature file for J39ZC exists\n",
      "Extract features from raw video for 75AX5\n",
      "Feature file for 75AX5 exists\n",
      "Feature file for 75AX5 exists\n",
      "Feature file for 75AX5 exists\n",
      "Feature file for 75AX5 exists\n",
      "Extract features from raw video for DML20\n",
      "Extract features from raw video for ABK63\n",
      "Extract features from raw video for TBU3U\n",
      "Extract features from raw video for 67RSR\n",
      "Extract features from raw video for TE5P7\n",
      "Feature file for TE5P7 exists\n",
      "Extract features from raw video for AKALB\n",
      "Feature file for AKALB exists\n",
      "Extract features from raw video for BD4P9\n",
      "Feature file for BD4P9 exists\n",
      "Feature file for BD4P9 exists\n",
      "Feature file for BD4P9 exists\n",
      "Extract features from raw video for J6TVB\n",
      "Feature file for J6TVB exists\n",
      "Feature file for J6TVB exists\n",
      "Extract features from raw video for 7CXYB\n",
      "Extract features from raw video for X1RBM\n",
      "Feature file for X1RBM exists\n",
      "Feature file for X1RBM exists\n",
      "Extract features from raw video for WT2C0\n",
      "Feature file for WT2C0 exists\n",
      "Extract features from raw video for PSPMA\n",
      "Feature file for PSPMA exists\n",
      "Extract features from raw video for 7BL9D\n",
      "Feature file for 7BL9D exists\n",
      "Extract features from raw video for AIOTI\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8de8feb1e474>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-57bfcb29698f>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m## Get Video Features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mvisual_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisual_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_video_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Time scaled to same size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-57bfcb29698f>\u001b[0m in \u001b[0;36mget_video_features\u001b[0;34m(self, vid)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m## If not compute at the moment from .mp4 video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Extract features from raw video for {vid}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_from_raw_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvid\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.mp4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-57bfcb29698f>\u001b[0m in \u001b[0;36mextract_from_raw_video\u001b[0;34m(self, input_path, vid)\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#input expected: [batch, in_channels, clip_frames, height, width]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                 \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m             \u001b[0mvis_embed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mvis_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get an iterator using iter()\n",
    "my_iter = iter(train_dataset)\n",
    "\n",
    "# iterate through it using next()\n",
    "while True:\n",
    "    try:\n",
    "        el = next(my_iter)\n",
    "    except StopIteration:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module loss\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def bce_rescale_loss(scores, masks, targets, cfg):\n",
    "    min_iou, max_iou, bias = cfg.MIN_IOU, cfg.MAX_IOU, cfg.BIAS\n",
    "    joint_prob = torch.sigmoid(scores) * masks\n",
    "    target_prob = (targets-min_iou)*(1-bias)/(max_iou-min_iou)\n",
    "    target_prob[target_prob > 0] += bias\n",
    "    target_prob[target_prob > 1] = 1\n",
    "    target_prob[target_prob < 0] = 0\n",
    "    loss = F.binary_cross_entropy(joint_prob, target_prob, reduction='none') * masks\n",
    "    loss_value = torch.sum(loss) / torch.sum(masks)\n",
    "    return loss_value, joint_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module dependences for module TAN\n",
    "\"\"\"\n",
    "from torch import nn\n",
    "'''from core.config import config\n",
    "import models.frame_modules as frame_modules\n",
    "import models.prop_modules as prop_modules\n",
    "import models.map_modules as map_modules\n",
    "import models.fusion_modules as fusion_modules\n",
    "'''\n",
    "#*********************************************************** FRAME POOL\n",
    "class FrameAvgPool(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        super(FrameAvgPool, self).__init__()\n",
    "        input_size = cfg.INPUT_SIZE\n",
    "        hidden_size = cfg.HIDDEN_SIZE\n",
    "        kernel_size = cfg.KERNEL_SIZE\n",
    "        stride = cfg.STRIDE\n",
    "        self.vis_conv = nn.Conv1d(input_size, hidden_size, 1, 1)\n",
    "        self.avg_pool = nn.AvgPool1d(kernel_size, stride)\n",
    "\n",
    "    def forward(self, visual_input):\n",
    "        vis_h = torch.relu(self.vis_conv(visual_input))\n",
    "        vis_h = self.avg_pool(vis_h)\n",
    "        return vis_h\n",
    "\n",
    "class FrameMaxPool(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, stride):\n",
    "        super(FrameMaxPool, self).__init__()\n",
    "        self.vis_conv = nn.Conv1d(input_size, hidden_size, 1, 1)\n",
    "        self.max_pool = nn.MaxPool1d(stride)\n",
    "\n",
    "    def forward(self, visual_input):\n",
    "        vis_h = torch.relu(self.vis_conv(visual_input))\n",
    "        vis_h = self.max_pool(vis_h)\n",
    "        return vis_h\n",
    "#*********************************************************** BASE FUSION\n",
    "class BaseFusion(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        super(BaseFusion, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        hidden_size = cfg.HIDDEN_SIZE\n",
    "        txt_input_size = cfg.TXT_INPUT_SIZE\n",
    "        txt_hidden_size = cfg.TXT_HIDDEN_SIZE\n",
    "        self.textual_encoder = nn.LSTM(txt_input_size, txt_hidden_size//2 if cfg.LSTM.BIDIRECTIONAL else txt_hidden_size,\n",
    "                                       num_layers=cfg.LSTM.NUM_LAYERS, bidirectional=cfg.LSTM.BIDIRECTIONAL, batch_first=True)\n",
    "        self.tex_linear = nn.Linear(txt_hidden_size, hidden_size)\n",
    "        self.vis_conv = nn.Conv2d(hidden_size, hidden_size, 1, 1)\n",
    "\n",
    "    def forward(self, textual_input, textual_mask, map_h, map_mask):\n",
    "        self.textual_encoder.flatten_parameters()\n",
    "        txt_h = self.textual_encoder(textual_input)[0] * textual_mask\n",
    "        txt_h = torch.stack([txt_h[i][torch.sum(mask).long() - 1] for i, mask in enumerate(textual_mask)])\n",
    "        txt_h = self.tex_linear(txt_h)[:,:,None,None]\n",
    "        map_h = self.vis_conv(map_h)\n",
    "        fused_h = F.normalize(txt_h * map_h) * map_mask\n",
    "        return fused_h\n",
    "\n",
    "#*********************************************************** PROP MOD\n",
    "class PropMaxPool(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(PropMaxPool, self).__init__()\n",
    "        num_layers = cfg.NUM_LAYERS\n",
    "        self.layers = nn.ModuleList(\n",
    "            [nn.Identity()]\n",
    "            +[nn.MaxPool1d(2, stride=1) for _ in range(num_layers-1)]\n",
    "        )\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, hidden_size, num_clips = x.shape\n",
    "        map_h = x.new_zeros(batch_size, hidden_size, num_clips, num_clips).cuda()\n",
    "        map_mask = x.new_zeros(batch_size, 1, num_clips, num_clips).cuda()\n",
    "\n",
    "        for dig_idx, pool in enumerate(self.layers):\n",
    "            x = pool(x)\n",
    "            start_idxs = [s_idx for s_idx in range(0, num_clips - dig_idx, 1)]\n",
    "            end_idxs = [s_idx + dig_idx for s_idx in start_idxs]\n",
    "            map_h[:, :, start_idxs, end_idxs] = x\n",
    "            map_mask[:, :, start_idxs, end_idxs] += 1\n",
    "\n",
    "        return map_h, map_mask\n",
    "class SparsePropMaxPool(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(SparsePropMaxPool, self).__init__()\n",
    "        self.num_scale_layers = cfg.NUM_SCALE_LAYERS\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        for scale_idx, num_layer in enumerate(self.num_scale_layers):\n",
    "            scale_layers = nn.ModuleList()\n",
    "            first_layer = nn.MaxPool1d(1,1) if scale_idx == 0 else nn.MaxPool1d(3,2)\n",
    "            rest_layers = [nn.MaxPool1d(2,1) for _ in range(1, num_layer)]\n",
    "            scale_layers.extend([first_layer]+rest_layers)\n",
    "            self.layers.append(scale_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        map_h_list = []\n",
    "        map_mask_list = []\n",
    "\n",
    "        for scale_idx, scale_layers in enumerate(self.layers):\n",
    "            batch_size, hidden_size, num_scale_clips = x.shape\n",
    "            num_scale_clips = num_scale_clips//scale_layers[0].stride\n",
    "            map_h = x.new_zeros(batch_size, hidden_size, num_scale_clips, num_scale_clips)\n",
    "            map_mask = x.new_zeros(batch_size, 1, num_scale_clips, num_scale_clips)\n",
    "            for i, layer in enumerate(scale_layers):\n",
    "                try:\n",
    "                    x = layer(x)\n",
    "                except:\n",
    "                    pass\n",
    "                scale_s_idxs = list(range(0, num_scale_clips - i, 1))\n",
    "                scale_e_idxs = [s_idx + i for s_idx in scale_s_idxs]\n",
    "                map_h[:,:,scale_s_idxs, scale_e_idxs] = x\n",
    "                map_mask[:,:,scale_s_idxs, scale_e_idxs] = 1\n",
    "            map_h_list.append(map_h)\n",
    "            map_mask_list.append(map_mask)\n",
    "\n",
    "        ori_map_h, ori_map_mask = self.recover_to_original_map(map_h_list, map_mask_list)\n",
    "        return ori_map_h, ori_map_mask\n",
    "\n",
    "    def recover_to_original_map(self, h_list, mask_list):\n",
    "        # resize to original scale\n",
    "        batch_size, hidden_size, ori_num_clips, _ = h_list[0].shape\n",
    "\n",
    "        ori_map_h = h_list[0].new_zeros(batch_size, hidden_size, ori_num_clips, ori_num_clips)\n",
    "        ori_map_mask = mask_list[0].new_zeros(batch_size, 1, ori_num_clips, ori_num_clips)\n",
    "        acum_layers = 0\n",
    "        stride = 1\n",
    "        for scale_layers, h, mask in zip(self.layers, h_list, mask_list):\n",
    "            num_scale_clips = h.shape[-1]\n",
    "            for i, layer in enumerate(scale_layers):\n",
    "                stride = stride * layer.stride\n",
    "                scale_s_idxs = list(range(0,num_scale_clips-i,1))\n",
    "                scale_e_idxs = [s_idx+i for s_idx in scale_s_idxs]\n",
    "                ori_s_idxs = list(range(0,ori_num_clips-acum_layers-i*stride,stride))\n",
    "                ori_e_idxs = [s_idx+acum_layers+i*stride for s_idx in ori_s_idxs]\n",
    "                ori_map_h[:,:, ori_s_idxs, ori_e_idxs] = h[:,:, scale_s_idxs, scale_e_idxs]\n",
    "                ori_map_mask[:,:, ori_s_idxs, ori_e_idxs] = 1\n",
    "\n",
    "            acum_layers += stride * (len(scale_layers)+1)\n",
    "\n",
    "        return ori_map_h, ori_map_mask\n",
    "\n",
    "class SparsePropConv(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(SparsePropConv, self).__init__()\n",
    "        self.num_scale_layers = cfg.NUM_SCALE_LAYERS\n",
    "        self.hidden_size = cfg.HIDDEN_SIZE\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        for scale_idx, num_layer in enumerate(self.num_scale_layers):\n",
    "            scale_layers = nn.ModuleList()\n",
    "            first_layer = nn.Conv1d(self.hidden_size, self.hidden_size, 1,1) if scale_idx == 0 else nn.Conv1d(self.hidden_size, self.hidden_size, 3, 2)\n",
    "            rest_layers = [nn.Conv1d(self.hidden_size, self.hidden_size, 2,1) for _ in range(1, num_layer)]\n",
    "            scale_layers.extend([first_layer]+rest_layers)\n",
    "            self.layers.append(scale_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        map_h_list = []\n",
    "        map_mask_list = []\n",
    "\n",
    "        for scale_idx, scale_layers in enumerate(self.layers):\n",
    "            batch_size, hidden_size, num_scale_clips = x.shape\n",
    "            num_scale_clips = num_scale_clips//scale_layers[0].stride[0]\n",
    "            map_h = x.new_zeros(batch_size, hidden_size, num_scale_clips, num_scale_clips)\n",
    "            map_mask = x.new_zeros(batch_size, 1, num_scale_clips, num_scale_clips)\n",
    "            for i, layer in enumerate(scale_layers):\n",
    "                x = layer(x)\n",
    "                scale_s_idxs = list(range(0, num_scale_clips - i, 1))\n",
    "                scale_e_idxs = [s_idx + i for s_idx in scale_s_idxs]\n",
    "                map_h[:,:,scale_s_idxs, scale_e_idxs] = x\n",
    "                map_mask[:,:,scale_s_idxs, scale_e_idxs] = 1\n",
    "            map_h_list.append(map_h)\n",
    "            map_mask_list.append(map_mask)\n",
    "\n",
    "\n",
    "        ori_map_h, ori_map_mask = self.recover_to_original_map(map_h_list, map_mask_list)\n",
    "\n",
    "        return ori_map_h, ori_map_mask\n",
    "\n",
    "    def recover_to_original_map(self, h_list, mask_list):\n",
    "        # resize to original scale\n",
    "        batch_size, hidden_size, ori_num_clips, _ = h_list[0].shape\n",
    "\n",
    "        ori_map_h = h_list[0].new_zeros(batch_size, hidden_size, ori_num_clips, ori_num_clips)\n",
    "        ori_map_mask = mask_list[0].new_zeros(batch_size, 1, ori_num_clips, ori_num_clips)\n",
    "        acum_layers = 0\n",
    "        stride = 1\n",
    "        for scale_layers, h, mask in zip(self.layers, h_list, mask_list):\n",
    "            num_scale_clips = h.shape[-1]\n",
    "            for i, layer in enumerate(scale_layers):\n",
    "                stride = stride * layer.stride[0]\n",
    "                scale_s_idxs = list(range(0,num_scale_clips-i,1))\n",
    "                scale_e_idxs = [s_idx+i for s_idx in scale_s_idxs]\n",
    "                ori_s_idxs = list(range(0,ori_num_clips-acum_layers-i*stride,stride))\n",
    "                ori_e_idxs = [s_idx+acum_layers+i*stride for s_idx in ori_s_idxs]\n",
    "                ori_map_h[:,:, ori_s_idxs, ori_e_idxs] = h[:,:, scale_s_idxs, scale_e_idxs]\n",
    "                ori_map_mask[:,:, ori_s_idxs, ori_e_idxs] = 1\n",
    "\n",
    "            acum_layers += stride * (len(scale_layers)+1)\n",
    "\n",
    "        return ori_map_h, ori_map_mask\n",
    "#*********************************************************** MAP CONV\n",
    "def get_padded_mask_and_weight(*args):\n",
    "    if len(args) == 2:\n",
    "        mask, conv = args\n",
    "        masked_weight = torch.round(F.conv2d(mask.clone().float(), torch.ones(1, 1, *conv.kernel_size).cuda(),\n",
    "                                             stride=conv.stride, padding=conv.padding, dilation=conv.dilation))\n",
    "    elif len(args) == 5:\n",
    "        mask, k, s, p, d = args\n",
    "        masked_weight = torch.round(F.conv2d(mask.clone().float(), torch.ones(1, 1, k, k).cuda(), stride=s, padding=p, dilation=d))\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    masked_weight[masked_weight > 0] = 1 / masked_weight[masked_weight > 0] #conv.kernel_size[0] * conv.kernel_size[1]\n",
    "    padded_mask = masked_weight > 0\n",
    "\n",
    "    return padded_mask, masked_weight\n",
    "class MapConv(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        super(MapConv, self).__init__()\n",
    "        input_size = cfg.INPUT_SIZE\n",
    "        hidden_sizes = cfg.HIDDEN_SIZES\n",
    "        kernel_sizes = cfg.KERNEL_SIZES\n",
    "        strides = cfg.STRIDES\n",
    "        paddings = cfg.PADDINGS\n",
    "        dilations = cfg.DILATIONS\n",
    "        self.convs = nn.ModuleList()\n",
    "        assert len(hidden_sizes) == len(kernel_sizes) \\\n",
    "               and len(hidden_sizes) == len(strides) \\\n",
    "               and len(hidden_sizes) == len(paddings) \\\n",
    "               and len(hidden_sizes) == len(dilations)\n",
    "        channel_sizes = [input_size]+hidden_sizes\n",
    "        for i, (k, s, p, d) in enumerate(zip(kernel_sizes, strides, paddings, dilations)):\n",
    "            self.convs.append(nn.Conv2d(channel_sizes[i], channel_sizes[i+1], k, s, p, d))\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        padded_mask = mask\n",
    "        for i, pred in enumerate(self.convs):\n",
    "            x = F.relu(pred(x))\n",
    "            padded_mask, masked_weight = get_padded_mask_and_weight(padded_mask, pred)\n",
    "            x = x * masked_weight\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module main model TAN\n",
    "\"\"\"\n",
    "class TAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TAN, self).__init__()\n",
    "\n",
    "        '''\n",
    "        self.frame_layer = getattr(frame_modules, config.TAN.FRAME_MODULE.NAME)(config.TAN.FRAME_MODULE.PARAMS)\n",
    "        self.prop_layer = getattr(prop_modules, config.TAN.PROP_MODULE.NAME)(config.TAN.PROP_MODULE.PARAMS)\n",
    "        self.fusion_layer = getattr(fusion_modules, config.TAN.FUSION_MODULE.NAME)(config.TAN.FUSION_MODULE.PARAMS)\n",
    "        self.map_layer = getattr(map_modules, config.TAN.MAP_MODULE.NAME)(config.TAN.MAP_MODULE.PARAMS)\n",
    "        '''\n",
    "        self.frame_layer = FrameAvgPool(config.TAN.FRAME_MODULE.PARAMS) #getattr(frame_modules, config.TAN.FRAME_MODULE.NAME)(config.TAN.FRAME_MODULE.PARAMS)\n",
    "        self.prop_layer = SparsePropMaxPool(config.TAN.PROP_MODULE.PARAMS) #getattr(prop_modules, config.TAN.PROP_MODULE.NAME)(config.TAN.PROP_MODULE.PARAMS)\n",
    "        self.fusion_layer = BaseFusion(config.TAN.FUSION_MODULE.PARAMS) #getattr(fusion_modules, config.TAN.FUSION_MODULE.NAME)(config.TAN.FUSION_MODULE.PARAMS)\n",
    "        self.map_layer = MapConv(config.TAN.MAP_MODULE.PARAMS) #getattr(map_modules, config.TAN.MAP_MODULE.NAME)(config.TAN.MAP_MODULE.PARAMS)\n",
    "        \n",
    "        self.pred_layer = nn.Conv2d(config.TAN.PRED_INPUT_SIZE, 1, 1, 1)\n",
    "\n",
    "    def forward(self, textual_input, textual_mask, visual_input):\n",
    "\n",
    "        vis_h = self.frame_layer(visual_input.transpose(1, 2))\n",
    "        map_h, map_mask = self.prop_layer(vis_h)\n",
    "        fused_h = self.fusion_layer(textual_input, textual_mask, map_h, map_mask)\n",
    "        fused_h = self.map_layer(fused_h, map_mask)\n",
    "        prediction = self.pred_layer(fused_h) * map_mask\n",
    "\n",
    "        return prediction, map_mask\n",
    "\n",
    "    def extract_features(self, textual_input, textual_mask, visual_input):\n",
    "        vis_h = self.frame_layer(visual_input.transpose(1, 2))\n",
    "        map_h, map_mask = self.prop_layer(vis_h)\n",
    "\n",
    "        fused_h = self.fusion_layer(textual_input, textual_mask, map_h, map_mask)\n",
    "        fused_h = self.map_layer(fused_h, map_mask)\n",
    "        prediction = self.pred_layer(fused_h) * map_mask\n",
    "\n",
    "        return fused_h, prediction, map_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAIN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_start\n",
      "EPOCH 0/100\n",
      "network\n",
      "network\n",
      "network\n",
      "network\n",
      "network\n",
      "[['Rank@1,mIoU@0.5', 'Rank@1,mIoU@0.7', 'Rank@5,mIoU@0.5', 'Rank@5,mIoU@0.7', 'mIoU'], ['1.18', '0.00', '21.18', '8.24', '4.60']]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0eab09f25826>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'on_test_forward'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mon_test_forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'on_test_end'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mon_test_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAX_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-793a4d505fb1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, network, iterator, maxepoch, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_update'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-793a4d505fb1>\u001b[0m in \u001b[0;36mhook\u001b[0;34m(self, name, state)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-0eab09f25826>\u001b[0m in \u001b[0;36mon_update\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEVAL_TRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mtrain_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_no_shuffle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mtrain_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisplay_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Rank@N,mIoU@M'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'miou'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'performance on training set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#eval.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mtable_message\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mtrain_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNO_VAL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-64fc85d912d2>\u001b[0m in \u001b[0;36mdisplay_results\u001b[0;34m(eval_result, miou, title)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m#for i in range(len(tious)*len(recalls)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m#    table.justify_columns[i] = 'center'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'table' is not defined"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "#import _init_paths\n",
    "import os\n",
    "import pprint\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "'''import datasets\n",
    "import models\n",
    "from core.config import config, update_config\n",
    "from core.engine import Engine\n",
    "from core.utils import AverageMeter\n",
    "from core import eval\n",
    "from core.utils import create_logger\n",
    "import models.loss as loss'''\n",
    "import math\n",
    "PATH = Path()\n",
    "\n",
    "\n",
    "'''\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "def reset_config(config, args):\n",
    "    if args.gpus:\n",
    "        config.GPUS = 0 #args.gpus\n",
    "    if args.workers:\n",
    "        config.WORKERS = 1 #args.workers\n",
    "    if args.dataDir:\n",
    "        config.DATA_DIR = #args.dataDir\n",
    "    if args.modelDir:\n",
    "        config.MODEL_DIR = #args.modelDir\n",
    "    if args.logDir:\n",
    "        config.LOG_DIR = #args.logDir\n",
    "    if args.verbose:\n",
    "        config.VERBOSE = #args.verbose\n",
    "    if args.tag:\n",
    "        config.TAG = #args.tag\n",
    "reset_config(config, _)\n",
    "logger, final_output_dir = create_logger(config, args.cfg, config.TAG)\n",
    "logger.info('\\n'+pprint.pformat(args))\n",
    "logger.info('\\n'+pprint.pformat(config))\n",
    "'''\n",
    "update_config(PATH.config_init_1())\n",
    "\n",
    "# cudnn related setting\n",
    "cudnn.benchmark = config.CUDNN.BENCHMARK\n",
    "torch.backends.cudnn.deterministic = config.CUDNN.DETERMINISTIC\n",
    "torch.backends.cudnn.enabled = config.CUDNN.ENABLED\n",
    "\n",
    "dataset_name = config.DATASET.NAME\n",
    "model_name = config.MODEL.NAME\n",
    "\n",
    "train_dataset = Charades(0) #getattr(datasets, dataset_name)('train')\n",
    "if config.TEST.EVAL_TRAIN:\n",
    "    eval_train_dataset = Charades(0) #getattr(datasets, dataset_name)('train')\n",
    "if not config.DATASET.NO_VAL:\n",
    "    val_dataset = Charades(1) #getattr(datasets, dataset_name)('val')\n",
    "test_dataset = Charades(1) #getattr(datasets, dataset_name)('test')\n",
    "\n",
    "model = TAN() #getattr(models, model_name)()\n",
    "if config.MODEL.CHECKPOINT and config.TRAIN.CONTINUE:\n",
    "    model_checkpoint = torch.load(config.MODEL.CHECKPOINT)\n",
    "    model.load_state_dict(model_checkpoint)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\" )\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=config.TRAIN.LR, betas=(0.9, 0.999), weight_decay=config.TRAIN.WEIGHT_DECAY)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=config.TRAIN.LR, momentum=0.9, weight_decay=config.TRAIN.WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=config.TRAIN.FACTOR, patience=config.TRAIN.PATIENCE, verbose=config.VERBOSE)\n",
    "\n",
    "def iterator(split):\n",
    "    if split == 'train':\n",
    "        dataloader = DataLoader(train_dataset,\n",
    "                                batch_size=config.TRAIN.BATCH_SIZE,\n",
    "                                shuffle=False,#config.TRAIN.SHUFFLE,\n",
    "                                num_workers=config.WORKERS,\n",
    "                                pin_memory=False,\n",
    "                                collate_fn=collate_fn)#datasets.collate_fn)\n",
    "    elif split == 'val':\n",
    "        dataloader = DataLoader(val_dataset,\n",
    "                                batch_size=config.TEST.BATCH_SIZE,\n",
    "                                shuffle=False,\n",
    "                                num_workers=config.WORKERS,\n",
    "                                pin_memory=False,\n",
    "                                collate_fn=collate_fn)#datasets.collate_fn)\n",
    "    elif split == 'test':\n",
    "        dataloader = DataLoader(test_dataset,\n",
    "                                batch_size=config.TEST.BATCH_SIZE,\n",
    "                                shuffle=False,\n",
    "                                num_workers=config.WORKERS,\n",
    "                                pin_memory=False,\n",
    "                                collate_fn=collate_fn)#datasets.collate_fn)\n",
    "    elif split == 'train_no_shuffle':\n",
    "        dataloader = DataLoader(eval_train_dataset,\n",
    "                                batch_size=config.TEST.BATCH_SIZE,\n",
    "                                shuffle=False,\n",
    "                                num_workers=config.WORKERS,\n",
    "                                pin_memory=False,\n",
    "                                collate_fn=collate_fn)#datasets.collate_fn)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "def network(sample):\n",
    "    print('network')\n",
    "    anno_idxs = sample['batch_anno_idxs']\n",
    "    textual_input = sample['batch_word_vectors'].cuda()\n",
    "    textual_mask = sample['batch_txt_mask'].cuda()\n",
    "    visual_input = sample['batch_vis_input'].cuda()\n",
    "    map_gt = sample['batch_map_gt'].cuda()\n",
    "    duration = sample['batch_duration']\n",
    "\n",
    "    prediction, map_mask = model(textual_input, textual_mask, visual_input)\n",
    "    loss_value, joint_prob = bce_rescale_loss(prediction, map_mask, map_gt, config.LOSS.PARAMS) #getattr(loss, config.LOSS.NAME)(prediction, map_mask, map_gt, config.LOSS.PARAMS)\n",
    "\n",
    "    sorted_times = None if model.training else get_proposal_results(joint_prob, duration)\n",
    "\n",
    "    return loss_value, sorted_times\n",
    "\n",
    "def get_proposal_results(scores, durations):\n",
    "    # assume all valid scores are larger than one\n",
    "    out_sorted_times = []\n",
    "    for score, duration in zip(scores, durations):\n",
    "        T = score.shape[-1]\n",
    "        sorted_indexs = np.dstack(np.unravel_index(np.argsort(score.cpu().detach().numpy().ravel())[::-1], (T, T))).tolist()\n",
    "        sorted_indexs = np.array([item for item in sorted_indexs[0] if item[0] <= item[1]]).astype(float)\n",
    "\n",
    "        sorted_indexs[:,1] = sorted_indexs[:,1] + 1\n",
    "        sorted_indexs = torch.from_numpy(sorted_indexs).cuda()\n",
    "        target_size = config.DATASET.NUM_SAMPLE_CLIPS // config.DATASET.TARGET_STRIDE\n",
    "        out_sorted_times.append((sorted_indexs.float() / target_size * duration).tolist())\n",
    "\n",
    "    return out_sorted_times\n",
    "\n",
    "def on_start(state):\n",
    "    print('on_start')\n",
    "    state['loss_meter'] = AverageMeter()\n",
    "    state['test_interval'] = int(len(train_dataset)/config.TRAIN.BATCH_SIZE*config.TEST.INTERVAL)\n",
    "    state['t'] = 1\n",
    "    model.train()\n",
    "    if config.VERBOSE:\n",
    "        state['progress_bar'] = tqdm(total=state['test_interval'])\n",
    "\n",
    "def on_forward(state):\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 10)\n",
    "    state['loss_meter'].update(state['loss'].item(), 1)\n",
    "\n",
    "def on_update(state):# Save All\n",
    "    if config.VERBOSE:\n",
    "        state['progress_bar'].update(1)\n",
    "\n",
    "    if state['t'] % state['test_interval'] == 0:\n",
    "        model.eval()\n",
    "        if config.VERBOSE:\n",
    "            state['progress_bar'].close()\n",
    "\n",
    "        loss_message = '\\niter: {} train loss {:.4f}'.format(state['t'], state['loss_meter'].avg)\n",
    "        table_message = ''\n",
    "        if config.TEST.EVAL_TRAIN:\n",
    "            train_state = engine.test(network, iterator('train_no_shuffle'), 'train')\n",
    "            train_table = display_results(train_state['Rank@N,mIoU@M'], train_state['miou'],'performance on training set')#eval.\n",
    "            table_message += '\\n'+ train_table\n",
    "        if not config.DATASET.NO_VAL:\n",
    "            val_state = engine.test(network, iterator('val'), 'val')\n",
    "            state['scheduler'].step(-val_state['loss_meter'].avg)\n",
    "            loss_message += ' val loss {:.4f}'.format(val_state['loss_meter'].avg)\n",
    "            val_state['loss_meter'].reset()\n",
    "            val_table = display_results(val_state['Rank@N,mIoU@M'], val_state['miou'],'performance on validation set')#eval.\n",
    "            table_message += '\\n'+ val_table\n",
    "\n",
    "        test_state = engine.test(network, iterator('test'), 'test')\n",
    "        loss_message += ' test loss {:.4f}'.format(test_state['loss_meter'].avg)\n",
    "        test_state['loss_meter'].reset()\n",
    "        test_table = display_results(test_state['Rank@N,mIoU@M'], test_state['miou'],'performance on testing set')#eval.\n",
    "        table_message += '\\n' + test_table\n",
    "\n",
    "        message = loss_message+table_message+'\\n'\n",
    "        logger.info(message)\n",
    "\n",
    "        saved_model_filename = os.path.join(config.MODEL_DIR,'{}/{}/iter{:06d}-{:.4f}-{:.4f}.pkl'.format(\n",
    "            dataset_name, model_name+'_'+config.DATASET.VIS_INPUT_TYPE,\n",
    "            state['t'], test_state['Rank@N,mIoU@M'][0,0], test_state['Rank@N,mIoU@M'][0,1]))\n",
    "\n",
    "        rootfolder1 = os.path.dirname(saved_model_filename)\n",
    "        rootfolder2 = os.path.dirname(rootfolder1)\n",
    "        rootfolder3 = os.path.dirname(rootfolder2)\n",
    "        if not os.path.exists(rootfolder3):\n",
    "            print('Make directory %s ...' % rootfolder3)\n",
    "            os.mkdir(rootfolder3)\n",
    "        if not os.path.exists(rootfolder2):\n",
    "            print('Make directory %s ...' % rootfolder2)\n",
    "            os.mkdir(rootfolder2)\n",
    "        if not os.path.exists(rootfolder1):\n",
    "            print('Make directory %s ...' % rootfolder1)\n",
    "            os.mkdir(rootfolder1)\n",
    "\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            torch.save(model.module.state_dict(), saved_model_filename)\n",
    "        else:\n",
    "            torch.save(model.state_dict(), saved_model_filename)\n",
    "\n",
    "\n",
    "        if config.VERBOSE:\n",
    "            state['progress_bar'] = tqdm(total=state['test_interval'])\n",
    "        model.train()\n",
    "        state['loss_meter'].reset()\n",
    "\n",
    "def on_end(state):\n",
    "    if config.VERBOSE:\n",
    "        state['progress_bar'].close()\n",
    "\n",
    "\n",
    "def on_test_start(state):\n",
    "    state['loss_meter'] = AverageMeter()\n",
    "    state['sorted_segments_list'] = []\n",
    "    if config.VERBOSE:\n",
    "        if state['split'] == 'train':\n",
    "            state['progress_bar'] = tqdm(total=math.ceil(len(train_dataset)/config.TEST.BATCH_SIZE))\n",
    "        elif state['split'] == 'val':\n",
    "            state['progress_bar'] = tqdm(total=math.ceil(len(val_dataset)/config.TEST.BATCH_SIZE))\n",
    "        elif state['split'] == 'test':\n",
    "            state['progress_bar'] = tqdm(total=math.ceil(len(test_dataset)/config.TEST.BATCH_SIZE))\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "def on_test_forward(state):\n",
    "    if config.VERBOSE:\n",
    "        state['progress_bar'].update(1)\n",
    "    state['loss_meter'].update(state['loss'].item(), 1)\n",
    "\n",
    "    min_idx = min(state['sample']['batch_anno_idxs'])\n",
    "    batch_indexs = [idx - min_idx for idx in state['sample']['batch_anno_idxs']]\n",
    "    sorted_segments = [state['output'][i] for i in batch_indexs]\n",
    "    state['sorted_segments_list'].extend(sorted_segments)\n",
    "\n",
    "def on_test_end(state):\n",
    "    annotations = state['iterator'].dataset.annotations\n",
    "    state['Rank@N,mIoU@M'], state['miou'] = eval_predictions(state['sorted_segments_list'], annotations, verbose=False)#eval.eval_predictions(state['sorted_segments_list'], annotations, verbose=False)\n",
    "    if config.VERBOSE:\n",
    "        state['progress_bar'].close()\n",
    "\n",
    "\n",
    "engine = Engine()\n",
    "engine.hooks['on_start'] = on_start\n",
    "engine.hooks['on_forward'] = on_forward\n",
    "engine.hooks['on_update'] = on_update\n",
    "engine.hooks['on_end'] = on_end\n",
    "engine.hooks['on_test_start'] = on_test_start\n",
    "engine.hooks['on_test_forward'] = on_test_forward\n",
    "engine.hooks['on_test_end'] = on_test_end\n",
    "engine.train(network,iterator('train'),maxepoch=config.TRAIN.MAX_EPOCH,optimizer=optimizer,scheduler=scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

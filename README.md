# Text-to-Video-Retrieval-Neural-Networkvia-using-Proxies-Learning

We address the problem of retrieving a specific moment
from a video by a natural language query. This is a challenging
problem because a target moment may have semantic
relations to other temporal moments in the untrimmed
video. Existing methods have some approaches to tackle
this challenge by modeling the temporal relations between
video moments. In this paper, we propose a novel model
where we make use of proxies that are learnable parameters
represents some high level characteristics. Our proposed
approach is capable of learning faster with a better accuracy.
We evaluate the proposed model on two challenging
benchmarks, i.e., Charades-STA and ActivityNet Captions
where our model has promising results.
